# Multimodality medical image fusion using directional total variation based linear spectral clustering in NSCT domain

DOI: 10.1038/s41598-025-26916-y Journal: Scientific Reports

**Authors:** Khan, Mohammad Zubair, Diwakar, Manoj, Srivastava, Prakash, Singh, Prabhishek, Pandey, Neeraj Kumar, Albuhairy, Mohammad Mahyoob, Algaraady, Jeehaan

1. Faculty of Computer and Information System ,  Islamic University of Madinah, Madinah, Saudi Arabia
2. Department of CSE, Graphic Era (Deemed to be) University, Dehradun, India
3. Graphic Era Hill University, Dehradun, India
4. School of Computer Science Engineering and Technology, Bennett University, Greater Noida, India
5. Languages and Translation Department, Taibah University, Medinah, Saudi Arabia
6. Energy, Industry, and Advanced Technologies Research Center, Taibah University, Madinah, Kingdom of Saudi Arabia
7. Languages and Translation College, Taiz University, Taiz, Yemen

## Abstract

In medical science, there is a challenge to find out critical information from the medical images by low vision disability medical experts. As a solution, we can enhance the medical images by fusing different modality images viz., CT-MRI which can be more informative. This article presents a new multi-modal medical image fusion architecture in non-subsampled contourlet transform (NSCT) domain which is shift-invariant over noisy medical images. Initially noise from medical images is reduced using a convolution neural network (CNN) approach. Furthermore, NSCT is applied in denoised source multi-modal images to obtain approximation and detailed parts. In approximation parts of both input images, the fusion operation is performed using Direction Total Variation enabled linear spectral clustering. Simlarly in detailed parts of both input images fusion operation is performed using sum modified laplacian (SML) approaches. By performing inverse operation on both modified approximation and detailed parts, final fused image is obtained. From qualitative and quantitative result analysis, it can be concluded that the proposed method is an essential means of ensuring that multi-modality images provide more reliable analytical results to analyze experimental outcomes and comparative research.

## Abstract

In medical science, there is a challenge to find out critical information from the medical images by low vision disability medical experts. As a solution, we can enhance the medical images by fusing different modality images viz., CT-MRI which can be more informative. This article presents a new multi-modal medical image fusion architecture in non-subsampled contourlet transform (NSCT) domain which is shift-invariant over noisy medical images. Initially noise from medical images is reduced using a convolution neural network (CNN) approach. Furthermore, NSCT is applied in denoised source multi-modal images to obtain approximation and detailed parts. In approximation parts of both input images, the fusion operation is performed using Direction Total Variation enabled linear spectral clustering. Simlarly in detailed parts of both input images fusion operation is performed using sum modified laplacian (SML) approaches. By performing inverse operation on both modified approximation and detailed parts, final fused image is obtained. From qualitative and quantitative result analysis, it can be concluded that the proposed method is an essential means of ensuring that multi-modality images provide more reliable analytical results to analyze experimental outcomes and comparative research.

## Data availability

The dataset analyzed during the current study is available from the corresponding author (i.e. Manoj Diwakar) on reasonable request.

## Acknowledgements

This scientific paper is derived from a research grant funded by Taibah University, Madinah, Kingdom of Saudi Arabia - with grant number (447151101).

## Funding

This scientific paper is derived from a research grant funded by Taibah University, Madinah, Kingdom of Saudi Arabia - with grant number (447151101).

## Author information

### Authors and Affiliations

Authors Mohammad Zubair Khan [View author publications](/search?author=Mohammad%20Zubair%20Khan) Search author on: [PubMed](https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&term=Mohammad%20Zubair%20Khan) [Google Scholar](https://scholar.google.co.uk/scholar?as_q=&num=10&btnG=Search+Scholar&as_epq=&as_oq=&as_eq=&as_occt=any&as_sauthors=%22Mohammad%20Zubair%20Khan%22&as_publication=&as_ylo=&as_yhi=&as_allsubj=all&hl=en) Manoj Diwakar [View author publications](/search?author=Manoj%20Diwakar) Search author on: [PubMed](https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&term=Manoj%20Diwakar) [Google Scholar](https://scholar.google.co.uk/scholar?as_q=&num=10&btnG=Search+Scholar&as_epq=&as_oq=&as_eq=&as_occt=any&as_sauthors=%22Manoj%20Diwakar%22&as_publication=&as_ylo=&as_yhi=&as_allsubj=all&hl=en) Prakash Srivastava [View author publications](/search?author=Prakash%20Srivastava) Search author on: [PubMed](https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&term=Prakash%20Srivastava) [Google Scholar](https://scholar.google.co.uk/scholar?as_q=&num=10&btnG=Search+Scholar&as_epq=&as_oq=&as_eq=&as_occt=any&as_sauthors=%22Prakash%20Srivastava%22&as_publication=&as_ylo=&as_yhi=&as_allsubj=all&hl=en) Prabhishek Singh [View author publications](/search?author=Prabhishek%20Singh) Search author on: [PubMed](https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&term=Prabhishek%20Singh) [Google Scholar](https://scholar.google.co.uk/scholar?as_q=&num=10&btnG=Search+Scholar&as_epq=&as_oq=&as_eq=&as_occt=any&as_sauthors=%22Prabhishek%20Singh%22&as_publication=&as_ylo=&as_yhi=&as_allsubj=all&hl=en) Neeraj Kumar Pandey [View author publications](/search?author=Neeraj%20Kumar%20Pandey) Search author on: [PubMed](https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&term=Neeraj%20Kumar%20Pandey) [Google Scholar](https://scholar.google.co.uk/scholar?as_q=&num=10&btnG=Search+Scholar&as_epq=&as_oq=&as_eq=&as_occt=any&as_sauthors=%22Neeraj%20Kumar%20Pandey%22&as_publication=&as_ylo=&as_yhi=&as_allsubj=all&hl=en) Mohammad Mahyoob Albuhairy [View author publications](/search?author=Mohammad%20Mahyoob%20Albuhairy) Search author on: [PubMed](https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&term=Mohammad%20Mahyoob%20Albuhairy) [Google Scholar](https://scholar.google.co.uk/scholar?as_q=&num=10&btnG=Search+Scholar&as_epq=&as_oq=&as_eq=&as_occt=any&as_sauthors=%22Mohammad%20Mahyoob%20Albuhairy%22&as_publication=&as_ylo=&as_yhi=&as_allsubj=all&hl=en) Jeehaan Algaraady [View author publications](/search?author=Jeehaan%20Algaraady) Search author on: [PubMed](https://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&term=Jeehaan%20Algaraady) [Google Scholar](https://scholar.google.co.uk/scholar?as_q=&num=10&btnG=Search+Scholar&as_epq=&as_oq=&as_eq=&as_occt=any&as_sauthors=%22Jeehaan%20Algaraady%22&as_publication=&as_ylo=&as_yhi=&as_allsubj=all&hl=en)

### Contributions

M.J.K. and M.D. : writing original draft; P.Sr., P.Si., N.K.P., M.M.A. and J.A. : writing, review, and editing.

### Corresponding author

Correspondence to [Manoj Diwakar](mailto:manoj.diwakar@gmail.com) .

## Ethics declarations

### Competing interests

The authors declare no competing interests.

## Additional information

### Publisher’s note

Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.

## Rights and permissions

Open Access This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the licensed material. You do not have permission under this licence to share adapted material derived from this article or parts of it. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit [http://creativecommons.org/licenses/by-nc-nd/4.0/](http://creativecommons.org/licenses/by-nc-nd/4.0/) .

[Reprints and permissions](https://s100.copyright.com/AppDispatchServlet?title=Multimodality%20medical%20image%20fusion%20using%20directional%20total%20variation%20based%20linear%20spectral%20clustering%20in%20NSCT%20domain&author=Mohammad%20Zubair%20Khan%20et%20al&contentID=10.1038%2Fs41598-025-26916-y&copyright=The%20Author%28s%29&publication=2045-2322&publicationDate=2026-02-04&publisherName=SpringerNature&orderBeanReset=true&oa=CC%20BY-NC-ND)

## About this article

[https://crossmark.crossref.org/dialog/?doi=10.1038/s41598-025-26916-y](https://crossmark.crossref.org/dialog/?doi=10.1038/s41598-025-26916-y) Cite this article Khan, M.Z., Diwakar, M., Srivastava, P. et al. Multimodality medical image fusion using directional total variation based linear spectral clustering in NSCT domain. Sci Rep (2026). https://doi.org/10.1038/s41598-025-26916-y [Download citation](https://citation-needed.springer.com/v2/references/10.1038/s41598-025-26916-y?format=refman&flavour=citation) Received : 05 May 2025 Accepted : 31 October 2025 Published : 04 February 2026 DOI : https://doi.org/10.1038/s41598-025-26916-y Share this article Anyone you share the following link with will be able to read this content: Get shareable link Sorry, a shareable link is not currently available for this article. Copy shareable link to clipboard Provided by the Springer Nature SharedIt content-sharing initiative Keywords [Multi-modal image fusion](/search?query=Multi-modal%20image%20fusion&facet-discipline="Science%2C%20Humanities%20and%20Social%20Sciences%2C%20multidisciplinary") [Medical imaging](/search?query=Medical%20imaging&facet-discipline="Science%2C%20Humanities%20and%20Social%20Sciences%2C%20multidisciplinary") [Non-subsampled contourlet transform](/search?query=Non-subsampled%20contourlet%20transform&facet-discipline="Science%2C%20Humanities%20and%20Social%20Sciences%2C%20multidisciplinary") [Convolution neural network](/search?query=Convolution%20neural%20network&facet-discipline="Science%2C%20Humanities%20and%20Social%20Sciences%2C%20multidisciplinary")
