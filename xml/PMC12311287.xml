<?xml version="1.0"  ?><!DOCTYPE pmc-articleset PUBLIC "-//NLM//DTD ARTICLE SET 2.0//EN" "https://dtd.nlm.nih.gov/ncbi/pmc/articleset/nlm-articleset-2.0.dtd"><pmc-articleset><article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xml:lang="en" article-type="research-article" dtd-version="1.4"><processing-meta base-tagset="archiving" mathml-version="3.0" table-model="xhtml" tagset-family="jats"><restricted-by>pmc</restricted-by></processing-meta><front><journal-meta><journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id><journal-id journal-id-type="iso-abbrev">Bioinformatics</journal-id><journal-id journal-id-type="pmc-domain-id">716</journal-id><journal-id journal-id-type="pmc-domain">bioinfo</journal-id><journal-id journal-id-type="publisher-id">bioinformatics</journal-id><journal-title-group><journal-title>Bioinformatics</journal-title></journal-title-group><issn pub-type="ppub">1367-4803</issn><issn pub-type="epub">1367-4811</issn><publisher><publisher-name>Oxford University Press</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmcid">PMC12311287</article-id><article-id pub-id-type="pmcid-ver">PMC12311287.1</article-id><article-id pub-id-type="pmcaid">12311287</article-id><article-id pub-id-type="pmcaiid">12311287</article-id><article-id pub-id-type="pmid">40680165</article-id><article-id pub-id-type="doi">10.1093/bioinformatics/btaf408</article-id><article-id pub-id-type="publisher-id">btaf408</article-id><article-version article-version-type="pmc-version">1</article-version><article-categories><subj-group subj-group-type="heading"><subject>Original Paper</subject><subj-group subj-group-type="category-toc-heading"><subject>Data and Text Mining</subject></subj-group></subj-group><subj-group subj-group-type="category-taxonomy-collection"><subject>AcademicSubjects/SCI01060</subject></subj-group></article-categories><title-group><article-title>BioGraphFusion: graph knowledge embedding for biological completion and reasoning</article-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0009-0002-0481-2340</contrib-id><name name-style="western"><surname>Lin</surname><given-names initials="Y">Yitong</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Data curation&#xA0;[equal]" vocab-term-identifier="">Data curation&#160;[equal]</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis" degree-contribution="equal">Formal analysis</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation" degree-contribution="equal">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology" degree-contribution="equal">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Validation" vocab-term-identifier="https://credit.niso.org/contributor-roles/validation">Validation</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization" degree-contribution="equal">Visualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Writing - original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft" degree-contribution="equal">Writing - original draft</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Writing - review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing" degree-contribution="equal">Writing - review &amp; editing</role><aff>
<institution>College of Computer Science and Technology, Zhejiang University of Technology</institution>
<addr-line>, 288 Liuhe Road, Xihu District</addr-line>, Hangzhou, Zhejiang Province, 310023, <country country="CN">China</country></aff><xref rid="btaf408-FM1" ref-type="author-notes"/></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">https://orcid.org/0009-0001-4871-6345</contrib-id><name name-style="western"><surname>He</surname><given-names initials="J">Jiaying</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Conceptualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/conceptualization">Conceptualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Data curation&#xA0;[equal]" vocab-term-identifier="">Data curation&#160;[equal]</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Formal analysis" vocab-term-identifier="https://credit.niso.org/contributor-roles/formal-analysis" degree-contribution="equal">Formal analysis</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation" degree-contribution="equal">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Methodology" vocab-term-identifier="https://credit.niso.org/contributor-roles/methodology" degree-contribution="equal">Methodology</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization" degree-contribution="equal">Visualization</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Writing - original draft" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-original-draft" degree-contribution="equal">Writing - original draft</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Writing - review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing" degree-contribution="equal">Writing - review &amp; editing</role><aff>
<institution>College of Computer Science and Technology, Zhejiang University of Technology</institution>
<addr-line>, 288 Liuhe Road, Xihu District</addr-line>, Hangzhou, Zhejiang Province, 310023, <country country="CN">China</country></aff><xref rid="btaf408-FM1" ref-type="author-notes"/></contrib><contrib contrib-type="author"><name name-style="western"><surname>Chen</surname><given-names initials="J">Jiahe</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation" degree-contribution="equal">Investigation</role><aff>
<institution>College of Computer Science and Technology, Zhejiang University of Technology</institution>
<addr-line>, 288 Liuhe Road, Xihu District</addr-line>, Hangzhou, Zhejiang Province, 310023, <country country="CN">China</country></aff></contrib><contrib contrib-type="author"><name name-style="western"><surname>Zhu</surname><given-names initials="X">Xinnan</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Investigation" vocab-term-identifier="https://credit.niso.org/contributor-roles/investigation" degree-contribution="supporting">Investigation</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Visualization" vocab-term-identifier="https://credit.niso.org/contributor-roles/visualization" degree-contribution="supporting">Visualization</role><aff>
<institution>College of Computer Science and Technology, Zhejiang University of Technology</institution>
<addr-line>, 288 Liuhe Road, Xihu District</addr-line>, Hangzhou, Zhejiang Province, 310023, <country country="CN">China</country></aff></contrib><contrib contrib-type="author" corresp="yes"><name name-style="western"><surname>Zheng</surname><given-names initials="J">Jianwei</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Funding acquisition" vocab-term-identifier="https://credit.niso.org/contributor-roles/funding-acquisition">Funding acquisition</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision" degree-contribution="lead">Supervision</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Writing - review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing" degree-contribution="equal">Writing - review &amp; editing</role><aff>
<institution>College of Computer Science and Technology, Zhejiang University of Technology</institution>
<addr-line>, 288 Liuhe Road, Xihu District</addr-line>, Hangzhou, Zhejiang Province, 310023, <country country="CN">China</country></aff><xref rid="btaf408-cor1" ref-type="corresp"/></contrib><contrib contrib-type="author" corresp="yes"><name name-style="western"><surname>Bo</surname><given-names initials="T">Tao</given-names></name><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Supervision" vocab-term-identifier="https://credit.niso.org/contributor-roles/supervision" degree-contribution="equal">Supervision</role><role vocab="credit" vocab-identifier="https://credit.niso.org" vocab-term="Writing - review &amp; editing" vocab-term-identifier="https://credit.niso.org/contributor-roles/writing-review-editing" degree-contribution="equal">Writing - review &amp; editing</role><aff>
<institution>Key Laboratory of Endocrine Glucose &amp; Lipids Metabolism, Department of Endocrinology, , Shandong Provincial Hospital Affiliated to Shandong First Medical University</institution>
<addr-line>, 324 Jingwu Road, Huaiyin District</addr-line>, Jinan, Shandong Province, 250021, <country country="CN">China</country></aff><xref rid="btaf408-cor1" ref-type="corresp"/></contrib></contrib-group><contrib-group><contrib contrib-type="editor"><name name-style="western"><surname>Lu</surname><given-names initials="Z">Zhiyong</given-names></name><role>Associate Editor</role></contrib></contrib-group><author-notes><corresp id="btaf408-cor1">Corresponding authors. Jianwei Zheng, College of Computer Science and Technology, Zhejiang University of Technology, 288 Liuhe Road, Xihu District, Hangzhou, Zhejiang Province, 310023, China. E-mail: <email>zjw@zjut.edu.cn</email>; Tao Bo,&#160;Key Laboratory of Endocrine Glucose &amp; Lipids Metabolism, Department of Endocrinology, Shandong Provincial Hospital Affiliated to Shandong First Medical University, 324 Jingwu Road, Huaiyin District, Jinan, Shandong Province, 250021, China. E-mail: <email>botao666666@126.com</email></corresp><fn id="btaf408-FM1"><label>&#8225;</label><p>= equal contributions.</p></fn></author-notes><pub-date pub-type="collection"><month>7</month><year>2025</year></pub-date><pub-date pub-type="epub" iso-8601-date="2025-07-18"><day>18</day><month>7</month><year>2025</year></pub-date><volume>41</volume><issue>7</issue><issue-id pub-id-type="pmc-issue-id">491965</issue-id><elocation-id>btaf408</elocation-id><history><date date-type="received"><day>15</day><month>3</month><year>2025</year></date><date date-type="rev-recd"><day>04</day><month>6</month><year>2025</year></date><date date-type="editorial-decision"><day>11</day><month>7</month><year>2025</year></date><date date-type="accepted"><day>15</day><month>7</month><year>2025</year></date><date date-type="corrected-typeset"><day>30</day><month>7</month><year>2025</year></date></history><pub-history><event event-type="pmc-release"><date><day>18</day><month>07</month><year>2025</year></date></event><event event-type="pmc-live"><date><day>31</day><month>07</month><year>2025</year></date></event><event event-type="pmc-last-change"><date iso-8601-date="2025-08-01 00:25:14.163"><day>01</day><month>08</month><year>2025</year></date></event></pub-history><permissions><copyright-statement>&#169; The Author(s) 2025. Published by Oxford University Press.</copyright-statement><copyright-year>2025</copyright-year><license><ali:license_ref specific-use="textmining" content-type="ccbylicense">https://creativecommons.org/licenses/by/4.0/</ali:license_ref><license-p>This is an Open Access article distributed under the terms of the Creative Commons Attribution License (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="https://creativecommons.org/licenses/by/4.0/">https://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted reuse, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><self-uri xmlns:xlink="http://www.w3.org/1999/xlink" content-type="pmc-pdf" xlink:href="btaf408.pdf"/><self-uri xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="btaf408.pdf"/><abstract><title>Abstract</title><sec id="s1"><title>Motivation</title><p>Biomedical knowledge graphs (KGs) are crucial for drug discovery and disease understanding, yet their completion and reasoning are challenging. Knowledge embedding (KE) methods capture global semantics but struggle with dynamic structural integration, while graph neural networks (GNNs) excel locally but often lack semantic understanding. Even ensemble approaches, including those leveraging language models, often fail to achieve a deep, adaptive, and synergistic co-evolution between semantic comprehension and structural learning. Addressing this critical gap in fostering continuous, reciprocal refinement between these two aspects in complex biomedical KGs is paramount.</p></sec><sec id="s2"><title>Results</title><p>We introduce BioGraphFusion, a novel framework for deeply synergistic semantic and structural learning. BioGraphFusion establishes a global semantic foundation via tensor decomposition, guiding an LSTM-driven mechanism to dynamically refine relation embeddings during graph propagation. This fosters adaptive interplay between semantic understanding and structural learning, further enhanced by query-guided subgraph construction and a hybrid scoring mechanism. Experiments across three key biomedical tasks demonstrate BioGraphFusion&#8217;s superior performance over state-of-the-art KE, GNN, and ensemble models. A case study on cutaneous malignant melanoma 1 highlights its ability to unveil biologically meaningful pathways.</p></sec><sec id="s3"><title>Availability and implementation</title><p>Source code and all data underlying this article are freely available in the GitHub repository at <ext-link xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="https://github.com/Y-TARL/BioGraphFusion" ext-link-type="uri">https://github.com/Y-TARL/BioGraphFusion</ext-link>.</p></sec></abstract><abstract abstract-type="graphical"><title>Graphical Abstract</title><p>
<fig position="float" id="btaf408-F5" orientation="portrait"><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="btaf408f5.jpg"/></fig>
</p></abstract><counts><page-count count="10"/></counts><custom-meta-group><custom-meta><meta-name>pmc-status-qastatus</meta-name><meta-value>0</meta-value></custom-meta><custom-meta><meta-name>pmc-status-live</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-status-embargo</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-status-released</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-open-access</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-olf</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-manuscript</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-legally-suppressed</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-pdf</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-has-supplement</meta-name><meta-value>yes</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-pdf-only</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-suppress-copyright</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-real-version</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-is-scanned-article</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-preprint</meta-name><meta-value>no</meta-value></custom-meta><custom-meta><meta-name>pmc-prop-in-epmc</meta-name><meta-value>yes</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec><title>1 Introduction</title><p>Knowledge graphs (KGs) are semantic networks that represent relationships between entities as a set of triples <inline-formula id="IE1"><mml:math id="IM1" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, where <italic toggle="yes">h</italic> and <italic toggle="yes">t</italic> denote the head and tail entities, respectively, and <italic toggle="yes">r</italic> represents the relation connecting them (<xref rid="btaf408-B22" ref-type="bibr">Wang <italic toggle="yes">et al.</italic> 2024a</xref>). These graphs model real-world concepts and their interactions through nodes (entities) and edges (relations). Specifically, biological KGs have extended this framework to encompass entities such as diseases, genes, drugs, chemicals, and proteins, facilitating a structured understanding of clinical knowledge.</p><p>Technically, large-scale biological KGs such as DisGeNET (<xref rid="btaf408-B13" ref-type="bibr">Pi&#241;ero <italic toggle="yes">et al.</italic> 2020</xref>), STITCH (<xref rid="btaf408-B18" ref-type="bibr">Szklarczyk <italic toggle="yes">et al.</italic> 2016</xref>), and SIDER (<xref rid="btaf408-B6" ref-type="bibr">Kuhn <italic toggle="yes">et al.</italic> 2016</xref>) are widely used in biomedical research, which support applications including disease gene prediction (<xref rid="btaf408-B21" ref-type="bibr">Vilela <italic toggle="yes">et al.</italic> 2023</xref>), drug&#8211;target interaction (<xref rid="btaf408-B14" ref-type="bibr">Qiao <italic toggle="yes">et al.</italic> 2024</xref>), and drug&#8211;drug correlation (<xref rid="btaf408-B23" ref-type="bibr">Wang <italic toggle="yes">et al.</italic> 2024b</xref>).</p><p>Many such tasks demand for practical techniques of knowledge graph completion (KGC) (<xref rid="btaf408-B3" ref-type="bibr">Chen <italic toggle="yes">et al.</italic> 2020</xref>) and knowledge graph reasoning (KGR) (<xref rid="btaf408-B8" ref-type="bibr">Liang <italic toggle="yes">et al.</italic> 2024</xref>). Fundamentally, both techniques involve predicting the answer to a query of the form (h, r, ?) (<xref rid="btaf408-B10" ref-type="bibr">Meng <italic toggle="yes">et al.</italic> 2024</xref>), to identify the missing tail entity. While both may be considered as link prediction, they differ: KGC primarily predicts missing direct links (entities or relations) by identifying patterns in existing graph data. Extending this, KGR is a broader task that infers complex or multi-step knowledge, often employing logical inference mechanisms, rule-based systems, or multi-hop path analysis to deduce unstated facts. Thus, KGC focuses on completing the KG based on observed patterns, while KGR derives new insights through deeper inferential processes.</p><p>For KGC and KGR, knowledge embedding (KE) and graph structure propagation (GSP) are prevalent approaches, as detailed in foundational works (<xref rid="btaf408-B19" ref-type="bibr">Tang <italic toggle="yes">et al.</italic> 2024</xref>; <xref rid="btaf408-B8" ref-type="bibr">Liang <italic toggle="yes">et al.</italic> 2024</xref>). KE, often termed a latent feature model (<xref rid="btaf408-B11" ref-type="bibr">Nickel <italic toggle="yes">et al.</italic> 2016</xref>), embeds entities and relations into continuous vector spaces, capturing semantic information to score candidate entities directly. For instance, RotatE (<xref rid="btaf408-B17" ref-type="bibr">Sun <italic toggle="yes">et al.</italic> 2019</xref>) models relations as rotations in complex space <inline-formula id="IE2"><mml:math id="IM2" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo>&#176;</mml:mo><mml:mi>r</mml:mi><mml:mo>&#8776;</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:math></inline-formula>), while CP-N3 (<xref rid="btaf408-B7" ref-type="bibr">Lacroix <italic toggle="yes">et al.</italic> 2018</xref>) enhances performance by factorizing higher-order interactions. While KE techniques excel at capturing semantics, they often overlook structural patterns&#8212;such as multi-hop paths&#8212;limiting their reasoning capabilities over complex, multi-relational biomedical graphs (<xref rid="btaf408-B9" ref-type="bibr">Liu <italic toggle="yes">et al.</italic> 2022</xref>; <xref rid="btaf408-B12" ref-type="bibr">Peng <italic toggle="yes">et al.</italic> 2023</xref>).</p><p>In contrast, GSP borrows its main architecture from graph neural networks (GNNs) (<xref rid="btaf408-B25" ref-type="bibr">Yu <italic toggle="yes">et al.</italic> 2021</xref>), which have significantly advanced network analysis by propagating messages between entities, thereby partially capturing topological information. Representatives such as GNN4DM (<xref rid="btaf408-B4" ref-type="bibr">G&#233;zsi and Antal 2024</xref>) demonstrate the power of these approaches in tasks like discovering overlapping functional disease modules through the integration of network topology and genomic data. However, these methods, while adept at structural modeling, often tend to overemphasize topological information at the expense of deeper semantic associations and the rich content of relations.</p><p>Recognizing the limitations of traditional KE and GSP methods, and with the advent of powerful pre-trained language models (LMs), more advanced approaches have emerged for KGC and KGR. These methods often seek to incorporate richer semantic understanding directly from textual data or find novel ways of integrating semantic and structural information, moving beyond the KE or GSP paradigms alone. For instance, KG-BERT (<xref rid="btaf408-B24" ref-type="bibr">Yao <italic toggle="yes">et al.</italic> 2019</xref>) uses pre-trained LMs to score textualized triples, prioritizing semantics but with high computational costs. Similarly, LASS (<xref rid="btaf408-B15" ref-type="bibr">Shen <italic toggle="yes">et al.</italic> 2022</xref>) attempts fusion by embedding natural language semantics with graph structure through LM fine-tuning and probabilistic reconstruction loss, yet its loss-mediated interaction limits deeply adaptive integration.</p><p>While these approaches significantly advanced semantic and structural learning for KGC and KGR, they underscore a persistent challenge: achieving deep, dynamic coupling where semantic guidance and structural propagation synergistically co-evolve. Many methods, despite innovations, still struggle with fully reciprocal, adaptive refinement between rich semantic understanding and nuanced structural learning. This critical gap&#8212;the difficulty in developing a framework that enables a mutually enhancing co-evolution between semantic and structural learning&#8212;motivates BioGraphFusion. BioGraphFusion is a novel framework designed for such a profound synergistic integration, which leverages semantic insight, primarily drawing from principles of KE for global context, and combines it with dynamic structural reasoning, inspired by GSP techniques. The overall goal is for joint optimization of node and relation embeddings, thereby addressing the limitations in achieving the deep and adaptive semantic-structural interplay seen in prior methods.</p><p>BioGraphFusion actualizes this for biomedical KGs by weaving global semantic modeling with dynamic structural reasoning. Initially, a canonical polyadic (CP) decomposition (<xref rid="btaf408-B5" ref-type="bibr">Kolda and Bader 2009</xref>) module establishes a global semantic foundation, extracting low-dimensional embeddings capturing overarching biological associations and cross-domain interactions. This global semantic framework then actively steers structural learning. An LSTM-based gating mechanism dynamically refines relation embeddings during message propagation, adapting them to evolving semantic contexts and enabling the model to better capture long-range dependencies crucial for complex biological pathways. Further, a query-guided subgraph construction component focuses structural exploration on pertinent biological regions, ensuring message passing and representation learning concentrate on relevant interactions. Finally, a hybrid scoring mechanism orchestrates synergy between these semantic and structural representations. Such balanced integration empowers the semantic model to guide dynamic refinement of graph-based representations, fostering deep optimization of intricate edge embeddings. This process ensures a reciprocal and adaptive refinement cycle, where semantic understanding and structural learning iteratively enhance each other.</p></sec><sec><title>2 Materials and methods</title><sec><title>2.1 Dataset overview and task design</title><p>To advance biological KG completion and reasoning, we introduce three tasks integrating multi-source biomedical data. First, the disease&#8211;gene association prediction task (<xref rid="btaf408-B22" ref-type="bibr">Wang <italic toggle="yes">et al.</italic> 2024a</xref>) identifies missing disease-related genes by leveraging a primary dataset enriched with drug-disease and protein-chemical information. Second, the protein&#8211;chemical interaction task focuses on identifying compounds that interact with specific proteins, using core interaction data supplemented by auxiliary associations. Finally, the cross-medical ontology reasoning task employs the UMLS Terminology (<xref rid="btaf408-B2" ref-type="bibr">Bodenreider 2004</xref>). This task functions as link prediction: given a head concept and relation type, the model predicts the tail concept, inferring diverse ontological relationships, including hierarchical and associative links. Detailed dataset statistics and integration protocols for all tasks are summarized in Section 1, available as <xref rid="sup1" ref-type="supplementary-material">supplementary data</xref> at <italic toggle="yes">Bioinformatics</italic> online.</p></sec><sec><title>2.2 Overview of BioGraphFusion</title><p>BioGraphFusion achieves high performance in biomedical completion and reasoning by fostering a deep synergistic interplay between KE and GSP principles. By incorporating global semantic knowledge from KEs to guide the graph propagation process, our proposal effectively captures both direct and long-range relationships in biomedical graphs.</p><p>As illustrated in <xref rid="btaf408-F1" ref-type="fig">Fig.&#160;1</xref>, BioGraphFusion comprises three key components. First, global biological tensor encoding (Section 2.2.2) employs CP decomposition to extract low-dimensional embeddings that encode latent biological associations. Second, query-guided subgraph construction and propagation (Section 2.2.3) iteratively builds a query-relevant subgraph by refining relations and propagating context-specific embeddings. Finally, these complementary aspects are unified through a hybrid scoring mechanism (Section 2.2.4). This mechanism integrates KE&#8217;s direct global semantic contributions with structural insights from the KE-informed GSP process, enabling a nuanced assessment of candidate predictions.</p><fig position="float" id="btaf408-F1" orientation="portrait"><label>Figure 1.</label><caption><p>Overview of the BioGraphFusion framework. (A) Knowledge graph construction: integrating biomedical datasets to form a unified knowledge graph for downstream tasks. (B) Query-specific processing: a two-step process involving (B1) global tensor decomposition that captures latent biological associations, and (B2) query initialization that guides the guide the subsequent process. (C) Subgraph construction and propagation: iteratively builds a query-relevant subgraph through neighborhood expansion and propagation, including (C1) relation refinement via LSTM, (C2) query-attention propagation with context-based attention weights, and (C3) biological relevance filtering to select the most pertinent entities. (D) Final subgraph. (E) Scoring integration that balances structural-semantic information and Prediction Example that selects the most promising predictions, with a focus on brain neoplasms.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="btaf408f1.jpg"/></fig><sec><title>2.2.1 Notations and problem setup</title><p>Let <inline-formula id="IE3"><mml:math id="IM3" display="inline" overflow="scroll"><mml:mrow><mml:mi>G</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="script">V</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">R</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">F</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="script">Q</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> be a biomedical KG integrating diverse fact triples from multiple sources for various tasks, as shown in <xref rid="btaf408-F1" ref-type="fig">Fig.&#160;1A</xref>. Here, <inline-formula id="IE4"><mml:math id="IM4" display="inline" overflow="scroll"><mml:mi mathvariant="script">V</mml:mi></mml:math></inline-formula> is the set of entities and <inline-formula id="IE5"><mml:math id="IM5" display="inline" overflow="scroll"><mml:mi mathvariant="script">R</mml:mi></mml:math></inline-formula> the set of relations. <inline-formula id="IE6"><mml:math id="IM6" display="inline" overflow="scroll"><mml:mi mathvariant="script">F</mml:mi></mml:math></inline-formula> is the set of factual triples, <inline-formula id="IE7"><mml:math id="IM7" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">F</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#8739;</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>&#8712;</mml:mo><mml:mi mathvariant="script">V</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mo>&#8712;</mml:mo><mml:mi mathvariant="script">R</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>, where head entity <italic toggle="yes">h</italic> and tail entity <italic toggle="yes">t</italic> are connected by relation <italic toggle="yes">r</italic>. To enhance graph diversity and model robustness, we also incorporate triples with reverse and identity relations (<xref rid="btaf408-B26" ref-type="bibr">Zhang and Yao 2022</xref>, <xref rid="btaf408-B27" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> 2023</xref>). <inline-formula id="IE8"><mml:math id="IM8" display="inline" overflow="scroll"><mml:mi mathvariant="script">Q</mml:mi></mml:math></inline-formula> contains query triples, <inline-formula id="IE9"><mml:math id="IM9" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">Q</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>a</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>&#8739;</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>a</mml:mi></mml:msub></mml:mrow><mml:mo>&#8712;</mml:mo><mml:mi mathvariant="script">V</mml:mi><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mo>&#8712;</mml:mo><mml:mi mathvariant="script">R</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></inline-formula>. Each query is of the form <inline-formula id="IE10"><mml:math id="IM10" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mo>?</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, with <inline-formula id="IE11"><mml:math id="IM11" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> as the unknown target entity. The objective for such queries is to predict <inline-formula id="IE12"><mml:math id="IM12" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, a task central to KGC and KGR aimed at enriching the KG.</p></sec><sec><title>2.2.2 Tensor decomposition and query initialization</title><p>Effective biomedical knowledge analysis hinges on understanding the global semantic landscape to foster a dynamic interplay between semantic insights and structural patterns. BioGraphFusion initiates this by establishing a global semantic foundation through tensor decomposition of the entire KG. This initial step provides a rich context essential for the subsequent integration of structural patterns with semantic understanding. For this critical stage, we employ CP decomposition (<xref rid="btaf408-B5" ref-type="bibr">Kolda and Bader 2009</xref>). CP is chosen as it directly factorizes the graph&#8217;s adjacency tensor to derive meaningful, low-dimensional latent embeddings for entities and relations. This factorization process adeptly captures fundamental relationships. Moreover, CP&#8217;s formulation as a low-rank tensor approximation offers a balance between model expressiveness and parsimony, ensuring computational efficiency and scalability vital for processing large-scale biomedical KGs.</p><p>The graph tensor <inline-formula id="IE13"><mml:math id="IM13" display="inline" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">T</mml:mi><mml:mo>&#8712;</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="script">V</mml:mi><mml:mo>|</mml:mo><mml:mo>&#215;</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant="script">R</mml:mi><mml:mo>|</mml:mo><mml:mo>&#215;</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant="script">V</mml:mi><mml:mo>|</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> is factorized via CP into three matrices: <inline-formula id="IE14"><mml:math id="IM14" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mi>h</mml:mi></mml:msub></mml:mrow><mml:mo>&#8712;</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="script">V</mml:mi><mml:mo>|</mml:mo><mml:mo>&#215;</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE15"><mml:math id="IM15" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mo>&#8712;</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="script">R</mml:mi><mml:mo>|</mml:mo><mml:mo>&#215;</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>, and <inline-formula id="IE16"><mml:math id="IM16" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>&#8712;</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="double-struck">R</mml:mi></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi mathvariant="script">V</mml:mi><mml:mo>|</mml:mo><mml:mo>&#215;</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula>. These matrices capture the latent semantic associations between entities and relations (<xref rid="btaf408-F1" ref-type="fig">Fig.&#160;1B1</xref>). The compatibility of any triple <inline-formula id="IE17"><mml:math id="IM17" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is then computed as:
<disp-formula id="E1"><label>(1)</label><mml:math id="M1" display="block" overflow="scroll"><mml:mrow><mml:mi>&#981;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>D</mml:mi></mml:munderover></mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mi>h</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mo>&#183;</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mi>r</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>&#183;</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE18"><mml:math id="IM18" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mi>h</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE19"><mml:math id="IM19" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mi>r</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>, and <inline-formula id="IE20"><mml:math id="IM20" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> are the <italic toggle="yes">d</italic>th components of the respective embeddings.</p><p>Subsequently, BioGraphFusion initializes query-specific representations directly from the CP-extracted matrices, ensuring a semantically meaningful starting point. Specifically, given a query <inline-formula id="IE21"><mml:math id="IM21" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mo>?</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, the entity embedding <inline-formula id="IE22"><mml:math id="IM22" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and the initial relation embedding <inline-formula id="IE23"><mml:math id="IM23" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mn>0</mml:mn></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> are retrieved from <inline-formula id="IE24"><mml:math id="IM24" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula id="IE25"><mml:math id="IM25" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">E</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, respectively (<xref rid="btaf408-F1" ref-type="fig">Fig.&#160;1B2</xref>). The initial node representation <inline-formula id="IE26"><mml:math id="IM26" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi>h</mml:mi></mml:mrow><mml:mn>0</mml:mn></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> is thus set to <inline-formula id="IE27"><mml:math id="IM27" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, establishing a query-grounded context before neighborhood expansion. Similarly, all entity and relation embeddings in the graph, including those encountered during propagation, are initialized from CP decomposition, preserving global structural information for subgraph construction and message passing.</p><fig position="float" id="btaf408-F2" orientation="portrait"><label>Figure 2.</label><caption><p>Ablation study results for BioGraphFusion (BGF) across three biomedical reasoning tasks: disease-gene prediction, protein-chemical interaction, and medical ontology reasoning. Performance metrics include MRR, Hit@1, and Hit@10. The full model is compared against four ablated variants: BGF-w/o GSP, BGF-R, BGF-w/o CRR, and BGF-w/o <inline-formula id="IE28"><mml:math id="IM28" display="inline" overflow="scroll"><mml:mi>&#981;</mml:mi></mml:math></inline-formula>.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="btaf408f2.jpg"/></fig></sec><sec><title>2.2.3 Query-guided subgraph construction</title><p>Biomedical KGs are vast and noisy, making it computationally impractical and error-prone to process the entire graph for each query. To address this, we employ a query-guided subgraph construction mechanism that selectively expands along semantically relevant paths (see <xref rid="btaf408-F1" ref-type="fig">Fig.&#160;1C</xref>), ensuring biological meaningfulness while filtering out spurious connections.</p><p>
<bold>Neighborhood expansion</bold> At each layer <inline-formula id="IE29"><mml:math id="IM29" display="inline" overflow="scroll"><mml:mi>&#8467;</mml:mi></mml:math></inline-formula>, the model expands the neighborhood for further propagation. Initially, at <inline-formula id="IE30"><mml:math id="IM30" display="inline" overflow="scroll"><mml:mrow><mml:mi>&#8467;</mml:mi><mml:mo>=</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:math></inline-formula>, the entity set <inline-formula id="IE31"><mml:math id="IM31" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script">V</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> contains only the query node <inline-formula id="IE32"><mml:math id="IM32" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>. For each entity <italic toggle="yes">h</italic> at layer <inline-formula id="IE33"><mml:math id="IM33" display="inline" overflow="scroll"><mml:mrow><mml:mi>&#8467;</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula>, we construct the candidate set <inline-formula id="IE34"><mml:math id="IM34" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script">C</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>&#8467;</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> by aggregating all direct neighbors of the current nodes:
<disp-formula id="E2"><label>(2)</label><mml:math id="M2" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script">C</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>&#8467;</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo>&#8746;</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mo>&#8712;</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script">V</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>&#8467;</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>{</mml:mo><mml:mi>t</mml:mi><mml:mo>&#8739;</mml:mo><mml:mo stretchy="false">(</mml:mo></mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#8712;</mml:mo><mml:mi mathvariant="script">F</mml:mi><mml:mo>}</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>In this step, the model gathers all possible entities that can serve as neighbors for the current nodes during propagation. On that basis, standard GNNs often update each node representation iteratively by gathering information from the surrounding entities. We also follow this step in our approach to constructing a candidate set <inline-formula id="IE35"><mml:math id="IM35" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script">C</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>&#8467;</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> to prepare for message propagation.</p><p>
<bold>Contextual relation refinement</bold> In many existing approaches, relation embeddings remain static or minimally updated, failing to account for contextual variations. However, in biomedical KGs, relations are rarely fixed; their meaning is shaped by the entities involved and the reasoning path. For instance, the relation &#8220;disease_gene&#8221; can imply different biological mechanisms depending on the specific genes or proteins connected. Furthermore, static embeddings struggle to model multi-step interactions, such as indirect associations mediated by proteins or chemicals.</p><p>To mitigate these limitations, we introduce a contextual relation refinement (CRR) module. LSTMs are chosen for their stateful transformation and gating mechanisms, which allow them to effectively model how relation meanings vary with entity context&#8212;a common scenario in biomedical KGs. Unlike simpler recurrent units (e.g., RNNs, GRUs), LSTMs excel at refining relation representations based on evolving semantic contexts from connected entities. This yields context-specific embeddings better suited for the dynamic, multi-step nature of biomedical relationships, iteratively updating relation embeddings as well as capturing context-dependent semantics and long-range dependencies (<xref rid="btaf408-B22" ref-type="bibr">Wang <italic toggle="yes">et al.</italic> 2024a</xref>). Specifically, for each triple <inline-formula id="IE36"><mml:math id="IM36" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, the LSTM updates the relation embedding <inline-formula id="IE37"><mml:math id="IM37" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mi>r</mml:mi><mml:mi>&#8467;</mml:mi></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> at layer <inline-formula id="IE38"><mml:math id="IM38" display="inline" overflow="scroll"><mml:mi>&#8467;</mml:mi></mml:math></inline-formula>, using the previous embedding <inline-formula id="IE39"><mml:math id="IM39" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mi>r</mml:mi><mml:mrow><mml:mi>&#8467;</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> as input and the head entity embedding <inline-formula id="IE40"><mml:math id="IM40" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mi>h</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> as the hidden state:
<disp-formula id="E3"><label>(3)</label><mml:math id="M3" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mi>r</mml:mi><mml:mi>&#8467;</mml:mi></mml:msubsup></mml:mrow><mml:mo>=</mml:mo><mml:mtext>LSTM</mml:mtext><mml:mo>&#160;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mi>r</mml:mi><mml:mrow><mml:mi>&#8467;</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mi>h</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>Through the internal gating mechanisms (including the forget gate <italic toggle="yes">f</italic>, input gate <italic toggle="yes">i</italic>, candidate memory cell <inline-formula id="IE41"><mml:math id="IM41" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mo>&#732;</mml:mo></mml:mover></mml:mrow></mml:mrow></mml:math></inline-formula>, memory cell <italic toggle="yes">c</italic>, and output gate <italic toggle="yes">o</italic>), LSTM selectively processes and retains relevant contextual information. It tailors the relation embedding to the connected entities. Similarly, the query relation <inline-formula id="IE42"><mml:math id="IM42" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mi>&#8467;</mml:mi></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> is updated by:
<disp-formula id="E4"><label>(4)</label><mml:math id="M4" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mi>&#8467;</mml:mi></mml:msubsup></mml:mrow><mml:mo>=</mml:mo><mml:mtext>LSTM</mml:mtext><mml:mo>&#160;</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mi>&#8467;</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>The dual LSTM adaptively refines both head-node and query relation representations based on semantic context from their respective entity embeddings. This dynamic modulation helps the model grasp nuanced relationships. Comparative experiments (see Section 8, available as <xref rid="sup1" ref-type="supplementary-material">supplementary data</xref> at <italic toggle="yes">Bioinformatics</italic> online for details) have confirmed that LSTMs are better than other alternatives, validating the capability of achieving deep semantic-structural coupling central to our model.</p><p>
<bold>Query-attention propagation</bold> Inspired by RED-GNN (<xref rid="btaf408-B26" ref-type="bibr">Zhang and Yao 2022</xref>), each candidate node <italic toggle="yes">t</italic> aggregates messages from its neighbors using a query-attentive mechanism (<xref rid="btaf408-F1" ref-type="fig">Fig.&#160;1C2</xref>). Specifically, the node representation at layer <inline-formula id="IE43"><mml:math id="IM43" display="inline" overflow="scroll"><mml:mi>&#8467;</mml:mi></mml:math></inline-formula> is updated as
<disp-formula id="E5"><mml:math id="M5" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mi>&#8467;</mml:mi></mml:msubsup></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>&#948;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mi>&#8467;</mml:mi></mml:msup></mml:mrow><mml:mo>&#183;</mml:mo><mml:mrow><mml:munder><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#8712;</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script">C</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>&#8467;</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mi>&#8467;</mml:mi></mml:msubsup></mml:mrow></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mi>h</mml:mi><mml:mrow><mml:mi>&#8467;</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mi>r</mml:mi><mml:mi>&#8467;</mml:mi></mml:msubsup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE44"><mml:math id="IM44" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mi>&#8467;</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></inline-formula> is a trainable weight matrix and <inline-formula id="IE45"><mml:math id="IM45" display="inline" overflow="scroll"><mml:mi>&#948;</mml:mi></mml:math></inline-formula> denotes the Tanh activation function. The attention weight <inline-formula id="IE46"><mml:math id="IM46" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mi>&#8467;</mml:mi></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>, computed as
<disp-formula id="E6"><mml:math id="M6" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi>&#945;</mml:mi></mml:mrow><mml:mrow><mml:mi>h</mml:mi><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mi>&#8467;</mml:mi></mml:msubsup></mml:mrow><mml:mo>=</mml:mo><mml:mi>&#963;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mi>&#945;</mml:mi><mml:mi>&#8467;</mml:mi></mml:msubsup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#8868;</mml:mo></mml:msup></mml:mrow><mml:mtext>ReLU</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mi>&#945;</mml:mi><mml:mi>&#8467;</mml:mi></mml:msubsup></mml:mrow><mml:mo>&#183;</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mi>h</mml:mi><mml:mrow><mml:mi>&#8467;</mml:mi><mml:mo>&#8722;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mi>r</mml:mi><mml:mi>&#8467;</mml:mi></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mi>&#8467;</mml:mi></mml:msubsup></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></disp-formula>integrates both local neighborhood features and the global query context, with <inline-formula id="IE47"><mml:math id="IM47" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mi>&#8467;</mml:mi></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> being the query-specific relation embedding refined by the LSTM module.</p><p>
<bold>Biological relevance filtering</bold> Following AdaProp (<xref rid="btaf408-B27" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> 2023</xref>), after node representations are updated, we compute an importance score for each candidate node <italic toggle="yes">t</italic>:
<disp-formula id="E7"><label>(5)</label><mml:math id="M7" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">W</mml:mi></mml:mrow><mml:mrow><mml:mtext>samp</mml:mtext></mml:mrow></mml:msub></mml:mrow><mml:mo>&#183;</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mi>t</mml:mi><mml:mi>&#8467;</mml:mi></mml:msubsup></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>This score quantifies the biological relevance of each node. We then filter the candidate set by retaining only the top <italic toggle="yes">K</italic> nodes. During training, the top <italic toggle="yes">K</italic> nodes are selected via a differentiable Gumbel-Softmax, while during inference, a conventional Softmax selection is applied:
<disp-formula id="E8"><label>(6)</label><mml:math id="M8" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script">V</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>&#8467;</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mo>=</mml:mo><mml:mtext>TopK</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">s</mml:mi></mml:mrow><mml:mi>t</mml:mi></mml:msub></mml:mrow><mml:mo>&#8739;</mml:mo><mml:mi>t</mml:mi><mml:mo>&#8712;</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script">C</mml:mi></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>&#8467;</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>For details on gradient-preserved hard selection, see Section 2, available as <xref rid="sup1" ref-type="supplementary-material">supplementary data</xref> at <italic toggle="yes">Bioinformatics</italic> online.</p><p>
<bold>Final subgraph construction</bold> Building upon this iteration, the final subgraph <inline-formula id="IE48"><mml:math id="IM48" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">G</mml:mi></mml:mrow><mml:mi>q</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is constructed over <inline-formula id="IE49"><mml:math id="IM49" display="inline" overflow="scroll"><mml:mi>&#8467;</mml:mi></mml:math></inline-formula> layers (<xref rid="btaf408-F1" ref-type="fig">Fig.&#160;1D</xref>):
<disp-formula id="E9"><label>(7)</label><mml:math id="M9" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">G</mml:mi></mml:mrow><mml:mi>q</mml:mi></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">V</mml:mi></mml:mrow><mml:mi>q</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">E</mml:mi></mml:mrow><mml:mi>q</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE50"><mml:math id="IM50" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">V</mml:mi></mml:mrow><mml:mi>q</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> denotes the set of selected entities and <inline-formula id="IE51"><mml:math id="IM51" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">E</mml:mi></mml:mrow><mml:mi>q</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> the relationships among them. This refined subgraph, enriched with contextually relevant information, is then used for downstream tasks such as KG completion and reasoning, ensuring that only the most pertinent interactions are propagated.</p></sec><sec><title>2.2.4 Joint formulation of scoring and loss functions</title><p>Focusing only on graph message or knowledge representation in the final scoring function may miss complementarity. Pure graph modeling may overlook deeper semantic relationships, whereas embedding methods might not capture fine-grained structural details. To better leverage the advantages of both perspectives, BioGraphFusion incorporates elements from KE and graph propagation into its final scoring function. For a triple <inline-formula id="IE52"><mml:math id="IM52" display="inline" overflow="scroll"><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>a</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula>, our score is defined as a weighted sum (see <xref rid="btaf408-F1" ref-type="fig">Fig.&#160;1E</xref>):
<disp-formula id="E10"><label>(8)</label><mml:math id="M10" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#732;</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>a</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi>&#955;</mml:mi><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>a</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#8722;</mml:mo><mml:mi>&#955;</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>&#981;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>a</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE53"><mml:math id="IM53" display="inline" overflow="scroll"><mml:mrow><mml:mi>&#955;</mml:mi><mml:mo>&#8712;</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mn>1</mml:mn><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math></inline-formula> balances the contributions from two key components. <inline-formula id="IE54"><mml:math id="IM54" display="inline" overflow="scroll"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>&#183;</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> represents the score derived from the KE-informed graph propagation process, capturing contextualized structural patterns, whereas <inline-formula id="IE55"><mml:math id="IM55" display="inline" overflow="scroll"><mml:mrow><mml:mi>&#981;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>&#183;</mml:mo><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> provides a direct global semantic score obtained through tensor decomposition. The hybrid design combines semantic knowledge with graph propagation through bidirectional interactions to refine structural representations. The component <inline-formula id="IE56"><mml:math id="IM56" display="inline" overflow="scroll"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>a</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></inline-formula> is computed from the final representation of the target entity obtained via iterative message passing:
<disp-formula id="E11"><label>(9)</label><mml:math id="M11" display="block" overflow="scroll"><mml:mrow><mml:mi>f</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>a</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="bold">w</mml:mi></mml:mrow><mml:mo>&#8868;</mml:mo></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">h</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mi>&#8467;</mml:mi></mml:msubsup></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math></disp-formula>and the tensor decomposition&#8211;based score, capturing the global biological context, is given by
<disp-formula id="E12"><label>(10)</label><mml:math id="M12" display="block" overflow="scroll"><mml:mrow><mml:mi>&#981;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>a</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>D</mml:mi></mml:munderover></mml:mrow><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow><mml:mo>&#183;</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>&#8467;</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow><mml:mo>&#183;</mml:mo><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></disp-formula>with <inline-formula id="IE57"><mml:math id="IM57" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula id="IE58"><mml:math id="IM58" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula>, and <inline-formula id="IE59"><mml:math id="IM59" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>d</mml:mi><mml:mo>,</mml:mo><mml:mi>&#8467;</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msubsup></mml:mrow></mml:mrow></mml:math></inline-formula> denoting the <italic toggle="yes">d</italic>th components of the CP embeddings for the query entity, target entity, and the refined query relation (updated at layer <inline-formula id="IE60"><mml:math id="IM60" display="inline" overflow="scroll"><mml:mi>&#8467;</mml:mi></mml:math></inline-formula> using an LSTM that incorporates <inline-formula id="IE61"><mml:math id="IM61" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>), respectively.</p><p>To train BioGraphFusion for biomedical completion and reasoning, we design a composite loss function with two objectives: (i) to maximize the likelihood of true relationships and (ii) to learn robust, generalizable embeddings. The primary component is a multi-class log-loss that encourages the model to assign higher scores to positive triples from the training set <inline-formula id="IE62"><mml:math id="IM62" display="inline" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">F</mml:mi></mml:mrow><mml:mrow><mml:mtext>tra</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> compared to negative candidates. Specifically, the log-loss is defined as:
<disp-formula id="E13"><mml:math id="M13" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8201;</mml:mo><mml:mtext>log</mml:mtext><mml:mo>&#8201;</mml:mo></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:munder><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>a</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>&#8712;</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">F</mml:mi></mml:mrow><mml:mrow><mml:mtext>tra</mml:mtext></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mo>&#8722;</mml:mo><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#732;</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>a</mml:mi></mml:msub></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>+</mml:mo><mml:mtext>log</mml:mtext><mml:mo>&#8201;</mml:mo><mml:mrow><mml:munder><mml:mo>&#8721;</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#8712;</mml:mo><mml:mi mathvariant="script">V</mml:mi></mml:mrow></mml:munder></mml:mrow><mml:mrow><mml:mo>&#8201;</mml:mo><mml:mtext>exp</mml:mtext><mml:mo>&#8201;</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:mrow><mml:mrow><mml:mover accent="true"><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mo>&#732;</mml:mo></mml:mover></mml:mrow></mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mo>,</mml:mo><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>In addition, following CP-N3 (<xref rid="btaf408-B7" ref-type="bibr">Lacroix <italic toggle="yes">et al.</italic> 2018</xref>), we incorporate an N3 regularization term. The primary motivation for this is to penalize large magnitudes in CP embeddings, thereby mitigating overfitting:
<disp-formula id="E14"><label>(11)</label><mml:math id="M14" display="block" overflow="scroll"><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">N</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>=</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant="bold">e</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>e</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:mo>|</mml:mo><mml:mi mathvariant="bold">e</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msup><mml:mrow/><mml:mi>&#8467;</mml:mi></mml:msup></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>+</mml:mo><mml:mo>|</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="bold">e</mml:mi></mml:mrow><mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>q</mml:mi></mml:mrow><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msubsup><mml:mrow><mml:mo>|</mml:mo></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:msubsup></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:math></disp-formula></p><p>To further validate our choice of N3, ablation studies on regularization were conducted (see Section 8, available as <xref rid="sup1" ref-type="supplementary-material">supplementary data</xref> at <italic toggle="yes">Bioinformatics</italic> online). These studies have confirmed the robustness of our model architecture, demonstrating that the model performs well and outperforms baselines even when employing naive regularizations (L1 or L2). Notably, the N3 regularization, generally yields superior results over alternatives. This advantage is attributed to the selection of the optimized configuration, reinforcing its suitability for our approach.</p><p>Thus, the overall loss is given by:
<disp-formula id="E15"><label>(12)</label><mml:math id="M15" display="block" overflow="scroll"><mml:mrow><mml:mi mathvariant="script">L</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="script">L</mml:mi></mml:mrow><mml:mrow><mml:mo>&#8201;</mml:mo><mml:mtext>log</mml:mtext><mml:mo>&#8201;</mml:mo></mml:mrow></mml:msub></mml:mrow><mml:mo>+</mml:mo><mml:mi>&#947;</mml:mi><mml:mrow><mml:msub><mml:mrow><mml:mi>R</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">N</mml:mi><mml:mn>3</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE63"><mml:math id="IM63" display="inline" overflow="scroll"><mml:mi>&#947;</mml:mi></mml:math></inline-formula> controls the regularization strength.</p></sec></sec></sec><sec><title>3 Results</title><sec><title>3.1 Implementation details</title><p>
<bold>Experimental setup.</bold> All experiments were implemented in Python using PyTorch v1.12.1 and PyTorch Geometric v2.0.9 on a single NVIDIA RTX 3090 GPU. Key hyperparameters were tuned over specific ranges; detailed configurations are provided in Section 3, available as <xref rid="sup1" ref-type="supplementary-material">supplementary data</xref> at <italic toggle="yes">Bioinformatics</italic> online.</p><p>
<bold>Evaluation metrics and baseline competitors.</bold> Following <xref rid="btaf408-B27" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> (2023)</xref> and <xref rid="btaf408-B26" ref-type="bibr">Zhang and Yao (2022)</xref>, we evaluate model performance using filtered ranking-based metrics: mean reciprocal rank and Hit@<italic toggle="yes">k</italic> (with <inline-formula id="IE64"><mml:math id="IM64" display="inline" overflow="scroll"><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:math></inline-formula> and 10). Detailed definitions of these metrics are provided in Section 4, available as <xref rid="sup1" ref-type="supplementary-material">supplementary data</xref> at <italic toggle="yes">Bioinformatics</italic> online. We benchmark BioGraphFusion against state-of-the-art methods from three major categories: KE models, GSP (GNN-based) approaches, and Ensemble methods. All baselines are implemented using publicly available code from the respective authors. Comprehensive descriptions of these baselines and implementation details are provided in Section 5, available as <xref rid="sup1" ref-type="supplementary-material">supplementary data</xref> at <italic toggle="yes">Bioinformatics</italic> online.</p><p>
<bold>Datasets and data integration.</bold> The disease&#8211;gene Prediction task uses 130&#160;820 disease&#8211;gene associations from DisGeNET (<xref rid="btaf408-B13" ref-type="bibr">Pi&#241;ero <italic toggle="yes">et al.</italic> 2020</xref>), partitioned 7:2:1 (training:validation:test) based on a specific fold from the KDGene (<xref rid="btaf408-B22" ref-type="bibr">Wang <italic toggle="yes">et al.</italic> 2024a</xref>) 10-fold cross-validation setup. For a comprehensive generalization assessment, we also conduct full 10-fold cross-validation (see Section 6, available as <xref rid="sup1" ref-type="supplementary-material">supplementary data</xref> at <italic toggle="yes">Bioinformatics</italic> online). <xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref>, available as <xref rid="sup1" ref-type="supplementary-material">supplementary data</xref> at <italic toggle="yes">Bioinformatics</italic> online include 14&#160;631 drug&#8211;disease relationships from SIDER (<xref rid="btaf408-B6" ref-type="bibr">Kuhn <italic toggle="yes">et al.</italic> 2016</xref>) and 277&#160;745 protein-chemical interactions from STITCH (<xref rid="btaf408-B18" ref-type="bibr">Szklarczyk <italic toggle="yes">et al.</italic> 2016</xref>). The Protein&#8211;Chemical Interaction task uses 23&#160;074 interaction triples from STITCH, filtered to the top 100 most frequent genes (<xref rid="btaf408-B23" ref-type="bibr">Wang <italic toggle="yes">et al.</italic> 2024b</xref>), and partitioned 7:2:1. To address data imbalance from extensive background knowledge, we cap supplementary samples at 15&#160;000 for disease&#8211;gene association prediction and 10&#160;000 for protein&#8211;chemical interaction. The medical ontology reasoning task is based on the UMLS Terminology (<xref rid="btaf408-B2" ref-type="bibr">Bodenreider 2004</xref>), pre-split into background, training, validation, and test sets as in prior work (<xref rid="btaf408-B26" ref-type="bibr">Zhang and Yao 2022</xref>, <xref rid="btaf408-B27" ref-type="bibr">Zhang <italic toggle="yes">et al.</italic> 2023</xref>). Further dataset and task details are in Section 1, available as <xref rid="sup1" ref-type="supplementary-material">supplementary data</xref> at <italic toggle="yes">Bioinformatics</italic> online.</p></sec><sec><title>3.2 Overall performance</title><p>
<xref rid="btaf408-T1" ref-type="table">Table&#160;1</xref> shows BioGraphFusion consistently outperforms KE, GNN, and Ensemble baselines across all three tasks. Regarding computational efficiency, Section 7, available as <xref rid="sup1" ref-type="supplementary-material">supplementary data</xref> at <italic toggle="yes">Bioinformatics</italic> online compares the inference time and MRR performance of BioGraphFusion with competitive baseline models on the UMLS dataset, analyzing the trade-off between their predictive performance and computational efficiency.</p><table-wrap position="float" id="btaf408-T1" orientation="portrait"><label>Table 1.</label><caption><p>Evaluation results of BioGraphFusion on biomedical completion and reasoning.<xref rid="tblfn1" ref-type="table-fn"><sup>a</sup></xref></p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col valign="top" align="left" span="1"/><col valign="top" align="left" span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/><col valign="top" align="char" char="." span="1"/></colgroup><thead><tr><th rowspan="2" colspan="1">Type</th><th rowspan="2" align="center" colspan="1">Models</th><th colspan="3" align="center" rowspan="1">Disease&#8211;gene prediction<hr/></th><th colspan="3" align="center" rowspan="1">Protein&#8211;chemical interaction<hr/></th><th colspan="3" align="center" rowspan="1">Medical ontology reasoning<hr/></th></tr><tr><th align="center" rowspan="1" colspan="1">MRR</th><th align="center" rowspan="1" colspan="1">Hit@1</th><th align="center" rowspan="1" colspan="1">Hit@10</th><th align="center" rowspan="1" colspan="1">MRR</th><th align="center" rowspan="1" colspan="1">Hit@1</th><th align="center" rowspan="1" colspan="1">Hit@10</th><th align="center" rowspan="1" colspan="1">MRR</th><th align="center" rowspan="1" colspan="1">Hit@1</th><th align="center" rowspan="1" colspan="1">Hit@10</th></tr></thead><tbody><tr><td rowspan="5" colspan="1">
<bold>KE</bold>
</td><td rowspan="1" colspan="1">RotatE</td><td rowspan="1" colspan="1">0.263</td><td rowspan="1" colspan="1">0.202</td><td rowspan="1" colspan="1">0.381</td><td rowspan="1" colspan="1">0.606</td><td rowspan="1" colspan="1">0.512</td><td rowspan="1" colspan="1">0.778</td><td rowspan="1" colspan="1">0.925</td><td rowspan="1" colspan="1">0.863</td><td rowspan="1" colspan="1">0.993</td></tr><tr><td rowspan="1" colspan="1">ComplEx</td><td rowspan="1" colspan="1">0.392</td><td rowspan="1" colspan="1">0.336</td><td rowspan="1" colspan="1">0.498</td><td rowspan="1" colspan="1">0.356</td><td rowspan="1" colspan="1">0.236</td><td rowspan="1" colspan="1">0.594</td><td rowspan="1" colspan="1">0.630</td><td rowspan="1" colspan="1">0.493</td><td rowspan="1" colspan="1">0.893</td></tr><tr><td rowspan="1" colspan="1">DistMult</td><td rowspan="1" colspan="1">0.258</td><td rowspan="1" colspan="1">0.198</td><td rowspan="1" colspan="1">0.375</td><td rowspan="1" colspan="1">0.120</td><td rowspan="1" colspan="1">0.045</td><td rowspan="1" colspan="1">0.276</td><td rowspan="1" colspan="1">0.569</td><td rowspan="1" colspan="1">0.461</td><td rowspan="1" colspan="1">0.797</td></tr><tr><td rowspan="1" colspan="1">CP-N3</td><td rowspan="1" colspan="1">0.207</td><td rowspan="1" colspan="1">0.151</td><td rowspan="1" colspan="1">0.312</td><td rowspan="1" colspan="1">0.089</td><td rowspan="1" colspan="1">0.029</td><td rowspan="1" colspan="1">0.189</td><td rowspan="1" colspan="1">0.300</td><td rowspan="1" colspan="1">0.134</td><td rowspan="1" colspan="1">0.750</td></tr><tr><td rowspan="1" colspan="1">KDGene</td><td rowspan="1" colspan="1">0.384</td><td rowspan="1" colspan="1">0.321</td><td rowspan="1" colspan="1">
<underline>0.523</underline>
</td><td rowspan="1" colspan="1">0.085</td><td rowspan="1" colspan="1">0.023</td><td rowspan="1" colspan="1">0.170</td><td rowspan="1" colspan="1">0.260</td><td rowspan="1" colspan="1">0.100</td><td rowspan="1" colspan="1">0.708</td></tr><tr><td rowspan="5" colspan="1">
<bold>GNN</bold>
</td><td rowspan="1" colspan="1">pLogicNet</td><td rowspan="1" colspan="1">0.228</td><td rowspan="1" colspan="1">0.173</td><td rowspan="1" colspan="1">0.335</td><td rowspan="1" colspan="1">0.591</td><td rowspan="1" colspan="1">0.564</td><td rowspan="1" colspan="1">0.630</td><td rowspan="1" colspan="1">0.842</td><td rowspan="1" colspan="1">0.772</td><td rowspan="1" colspan="1">0.965</td></tr><tr><td rowspan="1" colspan="1">CompGCN</td><td rowspan="1" colspan="1">0.252</td><td rowspan="1" colspan="1">0.191</td><td rowspan="1" colspan="1">0.367</td><td rowspan="1" colspan="1">0.614</td><td rowspan="1" colspan="1">0.576</td><td rowspan="1" colspan="1">0.676</td><td rowspan="1" colspan="1">0.907</td><td rowspan="1" colspan="1">0.867</td><td rowspan="1" colspan="1">0.994</td></tr><tr><td rowspan="1" colspan="1">DPMPN</td><td rowspan="1" colspan="1">0.293</td><td rowspan="1" colspan="1">0.235</td><td rowspan="1" colspan="1">0.393</td><td rowspan="1" colspan="1">0.632</td><td rowspan="1" colspan="1">0.614</td><td rowspan="1" colspan="1">0.729</td><td rowspan="1" colspan="1">0.930</td><td rowspan="1" colspan="1">0.899</td><td rowspan="1" colspan="1">0.980</td></tr><tr><td rowspan="1" colspan="1">AdaProp</td><td rowspan="1" colspan="1">0.345</td><td rowspan="1" colspan="1">0.296</td><td rowspan="1" colspan="1">0.438</td><td rowspan="1" colspan="1">
<underline>0.662</underline>
</td><td rowspan="1" colspan="1">
<underline>0.631</underline>
</td><td rowspan="1" colspan="1">0.781</td><td rowspan="1" colspan="1">
<underline>0.969</underline>
</td><td rowspan="1" colspan="1">
<underline>0.956</underline>
</td><td rowspan="1" colspan="1">
<bold>0.995</bold>
</td></tr><tr><td rowspan="1" colspan="1">RED-GNN</td><td rowspan="1" colspan="1">
<underline>0.389</underline>
</td><td rowspan="1" colspan="1">
<underline>0.332</underline>
</td><td rowspan="1" colspan="1">0.468</td><td rowspan="1" colspan="1">
<underline>0.662</underline>
</td><td rowspan="1" colspan="1">0.613</td><td rowspan="1" colspan="1">
<underline>0.782</underline>
</td><td rowspan="1" colspan="1">0.964</td><td rowspan="1" colspan="1">0.946</td><td rowspan="1" colspan="1">0.990</td></tr><tr><td rowspan="4" colspan="1">
<bold>Ensemble</bold>
</td><td rowspan="1" colspan="1">KG-BERT</td><td rowspan="1" colspan="1">&#8211;</td><td rowspan="1" colspan="1">&#8211;</td><td rowspan="1" colspan="1">&#8211;</td><td rowspan="1" colspan="1">&#8211;</td><td rowspan="1" colspan="1">&#8211;</td><td rowspan="1" colspan="1">&#8211;</td><td rowspan="1" colspan="1">0.774</td><td rowspan="1" colspan="1">0.649</td><td rowspan="1" colspan="1">0.967</td></tr><tr><td rowspan="1" colspan="1">StAR</td><td rowspan="1" colspan="1">0.247</td><td rowspan="1" colspan="1">0.192</td><td rowspan="1" colspan="1">0.361</td><td rowspan="1" colspan="1">0.426</td><td rowspan="1" colspan="1">0.326</td><td rowspan="1" colspan="1">0.700</td><td rowspan="1" colspan="1">0.834</td><td rowspan="1" colspan="1">0.720</td><td rowspan="1" colspan="1">0.976</td></tr><tr><td rowspan="1" colspan="1">LASS</td><td rowspan="1" colspan="1">0.211</td><td rowspan="1" colspan="1">0.167</td><td rowspan="1" colspan="1">0.324</td><td rowspan="1" colspan="1">0.401</td><td rowspan="1" colspan="1">0.314</td><td rowspan="1" colspan="1">0.691</td><td rowspan="1" colspan="1">0.908</td><td rowspan="1" colspan="1">0.952</td><td rowspan="1" colspan="1">0.983</td></tr><tr><td rowspan="1" colspan="1">Ours</td><td rowspan="1" colspan="1">0.429<xref rid="tblfn2" ref-type="table-fn">*</xref>*</td><td rowspan="1" colspan="1">0.377<xref rid="tblfn2" ref-type="table-fn">*</xref>*</td><td rowspan="1" colspan="1">0.529<xref rid="tblfn2" ref-type="table-fn">*</xref></td><td rowspan="1" colspan="1">0.702<xref rid="tblfn2" ref-type="table-fn">*</xref>*</td><td rowspan="1" colspan="1">0.657<xref rid="tblfn2" ref-type="table-fn">*</xref></td><td rowspan="1" colspan="1">0.795<xref rid="tblfn2" ref-type="table-fn">*</xref></td><td rowspan="1" colspan="1">0.974</td><td rowspan="1" colspan="1">0.963<xref rid="tblfn2" ref-type="table-fn">*</xref></td><td rowspan="1" colspan="1">
<underline>0.991</underline>
</td></tr></tbody></table><table-wrap-foot><fn id="tblfn1"><label>a</label><p>&#8220;-&#8221; means unavailable results. The best results are highlighted in bold and the second-best results are underlined.</p></fn><fn id="tblfn2"><label>*</label><p>denotes statistically improvements over the best baseline (*<italic toggle="yes">P</italic> &lt; .01, **<italic toggle="yes">P</italic> &lt; .001, paired <italic toggle="yes">t</italic>-test on five random seeds).</p></fn></table-wrap-foot></table-wrap><p>
<bold>KE methods</bold> reveal limitations in pure embedding approaches. ComplEx achieves moderate success in disease&#8211;gene association prediction (MRR 0.392) by modeling asymmetric relations, while RotatE (MRR 0.263) struggles despite its sophisticated rotation-based relation modeling. CP-N3&#8217;s poor performance in protein&#8211;chemical interaction is more telling. While CP-N3 uses tensor decomposition, a principle foundational to our approach, its standalone application, lacking crucial integration with structural learning, highlights the limitations of relying solely on this embedding technique. Even KDGene, engineered for disease-gene associations using interactional tensor decomposition, achieves only 0.384 MRR, showing semantic modeling alone, without adaptive structural guidance, cannot fully capture intricate biomedical dependencies.</p><p>
<bold>GNN approaches</bold> show different strengths and limitations. RED-GNN performs strongly in Disease-Gene Prediction (MRR 0.389), and AdaProp excels in Protein-Chemical Interaction (MRR 0.662). However, their weakness of reliance on structural patterns is apparent when compared to BioGraphFusion, which demonstrates consistent improvements in these tasks. While AdaProp has a slight edge in highly structured UMLS tasks, the merit diminishes in more semantically complex biomedical scenarios. While effective for local connectivity, pure structural propagation lacks the global semantic context needed to interpret biological relationships.</p><p>
<bold>Ensemble methods</bold> exhibit limitations in biomedical contexts. KG-BERT performs moderately in medical ontology reasoning (MRR 0.774), while StAR and LASS show limited effectiveness in Disease-Gene Association Prediction. A key constraint is their textual encoding components&#8217; limitation by sparse entity information&#8212;biomedical entities are often identifiers or technical terms, not descriptive text. This yields shallow semantic embeddings, hindering effective structural integration. While these methods try to bridge semantic understanding with structural patterns (StAR via Siamese encoding, LASS via joint fine-tuning), their limitations show that effective biomedical ensemble integration needs more than combining components.</p><p>
<bold>BioGraphFusion&#8217;s superior performance</bold> stems from its innovative deep coupling between semantic understanding and structural learning. Unlike existing methods that combine these paradigms statically, our model enables dynamic co-evolution where semantic insights guide structural reasoning while structural discoveries enrich semantic understanding. This deep coupling effectively models the intricate, context-dependent relationships in biomedical KGs, resulting in significant performance improvements across diverse tasks.</p></sec><sec><title>3.3 Ablation study</title><p>To evaluate individual component contributions in BioGraphFusion, we performed ablation studies on key modules for global semantics, GSP, and their hybrid scoring. Four targeted variants were implemented: (i) removal of GSP (BGF-w/o GSP): removes dynamic structural learning to assess GSP&#8217;s role in our model; (ii) random query encoding (BGF-R), in which the CP-derived query embeddings are replaced with randomly initialized vectors, disrupting semantic alignment; (iii) removal of contextual relation refinement (BGF-w/o CRR), which omits the LSTM-based updates for relation embeddings; and (iv) Elimination of the Tensor Decomposition Score (BGF-w/o <inline-formula id="IE65"><mml:math id="IM65" display="inline" overflow="scroll"><mml:mi>&#981;</mml:mi></mml:math></inline-formula>), which excludes the CP-based branch from the hybrid scoring function, leaving only the contextualized structural patterns to drive the scoring mechanism.</p><sec><title>3.3.1 Performance comparison</title><p>
<xref rid="btaf408-F2" ref-type="fig">Figure&#160;2</xref> summarizes the ablation study results, highlighting the distinct contributions of structural propagation (GSP) and KE components. Removing the GSP module (BGF-w/o GSP) leads to the most pronounced performance drop across all tasks, underscoring the essential role of dynamic structural learning in capturing topological dependencies and facilitating effective knowledge integration. This result demonstrates that structural propagation is indispensable for modeling complex biomedical relationships that rely on multi-hop and context-dependent interactions.</p><p>In contrast, the other three ablation variants&#8212;random query encoding (BGF-R), removal of contextual relation refinement (BGF-w/o CRR), and elimination of the tensor decomposition score (BGF-w/o <inline-formula id="IE66"><mml:math id="IM66" display="inline" overflow="scroll"><mml:mi>&#981;</mml:mi></mml:math></inline-formula>)&#8212;primarily target KE-related modules. Each of these modifications results in significant but distinct performance declines. BGF-R confirms the necessity of CP-based semantic initialization for maintaining meaningful entity representations; BGF-w/o CRR highlights the importance of LSTM-driven contextual refinement for relation embeddings; and BGF-w/o <inline-formula id="IE67"><mml:math id="IM67" display="inline" overflow="scroll"><mml:mi>&#981;</mml:mi></mml:math></inline-formula> demonstrates that optimal performance requires balancing global semantic signals with graph-derived structural patterns. Collectively, these findings confirm that our model&#8217;s success stems from the synergy between structural propagation and semantic embedding, not from either component alone.</p></sec><sec><title>3.3.2 Semantic embedding visualization</title><p>To assess KE components&#8217; impact on semantic representation, we visualize protein embeddings from the protein&#8211;chemical interaction task using t-SNE (<xref rid="btaf408-F3" ref-type="fig">Fig.&#160;3</xref>). We selected 10 chemical compounds (each linked to 50&#8211;100 proteins) and compared the full BioGraphFusion model with ablation variants BGF-w/o GSP, BGF-R, and BGF-w/o CRR. The BGF-w/o <inline-formula id="IE68"><mml:math id="IM68" display="inline" overflow="scroll"><mml:mi>&#981;</mml:mi></mml:math></inline-formula> variant was excluded as its scoring function primarily affects prediction scores, not embedding coordinates. Protein embeddings were obtained via post-propagation representations for GSP variants (full, BGF-R, BGF-w/o CRR), and via final CP embeddings for BGF-w/o GSP.</p><fig position="float" id="btaf408-F3" orientation="portrait"><label>Figure 3.</label><caption><p>t-SNE visualization of protein embeddings. Each subfigure shares the same proteins and each color represents proteins interacting with the same chemical compound, labeled by PubChem CID.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="btaf408f3.jpg"/></fig><p>The t-SNE visualizations in <xref rid="btaf408-F3" ref-type="fig">Fig.&#160;3</xref> illustrate progressive improvement in semantic coherence as key architectural components are integrated. The full BioGraphFusion model produces optimally tight and well-separated protein embeddings for each chemical compound, showing strong intra-cluster cohesion and inter-cluster separation. Conversely, BGF-w/o GSP (relying solely on initial CP embeddings) shows the most diffuse clustering with indistinct inter-group boundaries, highlighting GSP&#8217;s role in refining entity distinctions. BGF-R (with random query embeddings) exhibits clustering with significant overlap, confirming that effective GSP depends on high-quality initial semantic representations. BGF-w/o CRR shows clearer clustering than the previous two variants (benefiting from CP initialization and GSP), yet its clusters are less separated than the full model, emphasizing the crucial role of LSTM-driven relation refinement in forming clear, coherent clusters. These results confirm that CP initialization, dynamic GSP, and LSTM relation refinement each make unique contributions to meaningful biomedical entity representations. Visualization results for competitive baselines in Section 9, available as <xref rid="sup1" ref-type="supplementary-material">supplementary data</xref> at <italic toggle="yes">Bioinformatics</italic> online generally show more diffuse embedding clusters, further demonstrating BioGraphFusion&#8217;s effectiveness.</p></sec></sec><sec><title>3.4 Hyperparameter sensitivity analysis</title><p>We conducted extensive hyperparameter tuning on the disease&#8211;gene prediction task to examine the impact of key parameters on the final performance of BioGraphFusion. In our experiments, we varied the batch size, embedding dimension <italic toggle="yes">D</italic>, fusion weight <inline-formula id="IE69"><mml:math id="IM69" display="inline" overflow="scroll"><mml:mi>&#955;</mml:mi></mml:math></inline-formula>, and the number of propagation steps <inline-formula id="IE70"><mml:math id="IM70" display="inline" overflow="scroll"><mml:mi>&#8467;</mml:mi></mml:math></inline-formula>. Our results on the disease&#8211;gene dataset indicate optimal performance with a batch size of 16, an embedding dimension <inline-formula id="IE71"><mml:math id="IM71" display="inline" overflow="scroll"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>32</mml:mn></mml:mrow></mml:math></inline-formula>, a fusion weight <inline-formula id="IE72"><mml:math id="IM72" display="inline" overflow="scroll"><mml:mrow><mml:mi>&#955;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.7</mml:mn></mml:mrow></mml:math></inline-formula>, and <inline-formula id="IE73"><mml:math id="IM73" display="inline" overflow="scroll"><mml:mrow><mml:mi>&#8467;</mml:mi><mml:mo>=</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:math></inline-formula> propagation steps. Notably, the model enjoys robustness to batch size variations, while an embedding dimension of <inline-formula id="IE74"><mml:math id="IM74" display="inline" overflow="scroll"><mml:mrow><mml:mi>D</mml:mi><mml:mo>=</mml:mo><mml:mn>32</mml:mn></mml:mrow></mml:math></inline-formula> is found to effectively capture semantic details without over-parameterization. Tuning <inline-formula id="IE75"><mml:math id="IM75" display="inline" overflow="scroll"><mml:mi>&#955;</mml:mi></mml:math></inline-formula> and <inline-formula id="IE76"><mml:math id="IM76" display="inline" overflow="scroll"><mml:mi>&#8467;</mml:mi></mml:math></inline-formula> reveals critical balances: <inline-formula id="IE77"><mml:math id="IM77" display="inline" overflow="scroll"><mml:mrow><mml:mi>&#955;</mml:mi><mml:mo>=</mml:mo><mml:mn>0.7</mml:mn></mml:mrow></mml:math></inline-formula> optimally harmonizes structural propagation with global semantic embeddings, while <inline-formula id="IE78"><mml:math id="IM78" display="inline" overflow="scroll"><mml:mrow><mml:mi>&#8467;</mml:mi><mml:mo>=</mml:mo><mml:mn>6</mml:mn></mml:mrow></mml:math></inline-formula> propagation step effectively balances information aggregation against over-smoothing. This careful hyperparameter calibration is vital for maximizing model performance on biomedical tasks. Further details are in Section 10, available as <xref rid="sup1" ref-type="supplementary-material">supplementary data</xref> at <italic toggle="yes">Bioinformatics</italic> online.</p></sec><sec><title>3.5 Case analysis of cutaneous malignant melanoma 1</title><sec><title>3.5.1 Pathogenic gene prediction</title><p>We used BioGraphFusion to predict ten candidate genes for cutaneous malignant melanoma 1 (CMM1), including two known disease-associated genes (CDKN2D and CDK4) and eight novel candidates (<xref rid="btaf408-T2" ref-type="table">Table&#160;2</xref>). To validate these predictions (Pred.), we cross-referenced the candidates against three independent databases: PubMed (using PMIDs), MalaCards and ClinVar. We found that seven of the eight novel candidate genes&#8212;AKT1 (rank 3), NF1 (rank 5), OCA2 (rank 6), TP53 (rank 7), TYRP1 (rank 8), TYR (rank 9), and NRAS (rank 10)&#8212;are documented in both MalaCards and ClinVar, indicating established associations with melanoma or related conditions. Additionally, PubMed searches revealed literature support for the co-occurrence of CMM1 with all eight novel candidates.</p><table-wrap position="float" id="btaf408-T2" orientation="portrait"><label>Table 2.</label><caption><p>For CMM1, top 10 candidate gene predicted by BioGraphFusion.</p></caption><table frame="hsides" rules="groups"><colgroup span="1"><col valign="top" align="left" span="1"/><col valign="top" align="left" span="1"/><col valign="top" align="left" span="1"/><col valign="top" align="center" span="1"/><col valign="top" align="center" span="1"/></colgroup><thead><tr><th rowspan="1" colspan="1">Rank</th><th rowspan="1" colspan="1">Pred.</th><th rowspan="1" colspan="1">PMIDs</th><th rowspan="1" colspan="1">MalaCards</th><th rowspan="1" colspan="1">ClinVar</th></tr></thead><tbody><tr><td rowspan="1" colspan="1">1</td><td rowspan="1" colspan="1">CDKN2D<xref rid="tblfn3" ref-type="table-fn"><sup>a</sup></xref></td><td rowspan="1" colspan="1">&#8211;</td><td rowspan="1" colspan="1">&#8211;</td><td rowspan="1" colspan="1">&#8211;</td></tr><tr><td rowspan="1" colspan="1">2</td><td rowspan="1" colspan="1">CDK4D<xref rid="tblfn3" ref-type="table-fn"><sup>a</sup></xref></td><td rowspan="1" colspan="1">&#8211;</td><td rowspan="1" colspan="1">&#8211;</td><td rowspan="1" colspan="1">&#8211;</td></tr><tr><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">AKT1</td><td rowspan="1" colspan="1">38275910,39659584</td><td rowspan="1" colspan="1">&#10003;</td><td rowspan="1" colspan="1">&#10003;</td></tr><tr><td rowspan="1" colspan="1">4</td><td rowspan="1" colspan="1">HPS1</td><td rowspan="1" colspan="1">15982315,23084991</td><td rowspan="1" colspan="1"/><td rowspan="1" colspan="1"/></tr><tr><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">NF1</td><td rowspan="1" colspan="1">38179395,37965626</td><td rowspan="1" colspan="1">&#10003;</td><td rowspan="1" colspan="1">&#10003;</td></tr><tr><td rowspan="1" colspan="1">6</td><td rowspan="1" colspan="1">OCA2</td><td rowspan="1" colspan="1">37646013,37568588</td><td rowspan="1" colspan="1">&#10003;</td><td rowspan="1" colspan="1">&#10003;</td></tr><tr><td rowspan="1" colspan="1">7</td><td rowspan="1" colspan="1">TP53</td><td rowspan="1" colspan="1">24919155,38667459</td><td rowspan="1" colspan="1">&#10003;</td><td rowspan="1" colspan="1">&#10003;</td></tr><tr><td rowspan="1" colspan="1">8</td><td rowspan="1" colspan="1">TYRP1</td><td rowspan="1" colspan="1">37646013,37239381</td><td rowspan="1" colspan="1">&#10003;</td><td rowspan="1" colspan="1">&#10003;</td></tr><tr><td rowspan="1" colspan="1">9</td><td rowspan="1" colspan="1">TYR</td><td rowspan="1" colspan="1">19578364,18563784</td><td rowspan="1" colspan="1">&#10003;</td><td rowspan="1" colspan="1">&#10003;</td></tr><tr><td rowspan="1" colspan="1">10</td><td rowspan="1" colspan="1">NRAS</td><td rowspan="1" colspan="1">38275910,38183141</td><td rowspan="1" colspan="1">&#10003;</td><td rowspan="1" colspan="1">&#10003;</td></tr></tbody></table><table-wrap-foot><fn id="tblfn3"><label>a</label><p>These genes predicted by BioGraphFusion are in the test set.</p></fn></table-wrap-foot></table-wrap></sec><sec><title>3.5.2 Pathway enrichment and protein&#8211;protein interaction analysis</title><p>To evaluate the biological relevance of both known genes and the predictions for CMM1, we performed a KEGG pathway enrichment analysis. <xref rid="btaf408-F4" ref-type="fig">Figure&#160;4A</xref> presents the top 12 enriched pathways; notably, the &#8220;Melanoma&#8221; pathway shows the strongest enrichment (FDR&#8201;=&#8201;2.20e&#8722;26) with 18 prominently represented genes. In addition, pathways associated with Glioma and non-small cell lung cancer were also enriched, further supporting the biological plausibility of the candidate genes.</p><fig position="float" id="btaf408-F4" orientation="portrait"><label>Figure 4.</label><caption><p>Case study. (A) Analysis of KEGG pathway enrichment for the benchmark. The bubble chart shows significantly enriched pathways related to melanoma pathways. (B) Link visualization of known and predicted genes for melanoma on the PPI network. (C) Pathway predicted by BioGraphFusion from query disease CMM1 to melanoma-associated genes reveals a biologically plausible mechanistic link between CMM1 and established melanoma genes.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" position="float" orientation="portrait" xlink:href="btaf408f4.jpg"/></fig><p>We further employed CMM1 as an illustrative example to evaluate the network proximity and functional coherence between genes in the train set and the candidate genes predicted by BioGraphFusion. For this analysis, we retain all 11 genes from the training set and 2 genes from the testing set of the DisGeNET dataset, and extract the top 50 candidate genes predicted by BioGraphFusion. The resulting protein&#8211;protein interaction network (<xref rid="btaf408-F4" ref-type="fig">Fig.&#160;4B</xref>) exhibits markedly denser connectivity than would be expected by chance (<italic toggle="yes">P</italic>&#8201;=&#8201;4.669E&#8722;86, binomial test). Detailed connectivity statistics and analysis are provided in Section 11, available as <xref rid="sup1" ref-type="supplementary-material">supplementary data</xref> at <italic toggle="yes">Bioinformatics</italic> online. This dense interconnectivity suggests that the candidates are functionally related to the known genes, reinforcing the biological relevance of our predictions.</p></sec><sec><title>3.5.3 Pathway reasoning and biological validation</title><p>By analyzing inference pathways that connect candidate genes to known disease ones, we aim to infer their functional relationships to discover the causative mechanism. For example, analyzing pathways linking disease CMM1 to known melanoma-associated genes CDKN2D and CDK4 (<xref rid="btaf408-F4" ref-type="fig">Fig.&#160;4C</xref>), with edge thickness representing attention weights, revealed a key pathway (CMM1 &#8594; MC1R &#8594; Mole &#8594; CDK4/CDKN2D) offering novel insights into melanoma pathogenesis.</p><p>To further understand the mechanisms our model holds, we examined the inferred CMM1 &#8594; MC1R &#8594; Mole pathway, strongly backed by existing biological evidence. Research by <xref rid="btaf408-B16" ref-type="bibr">Su <italic toggle="yes">et al.</italic> (2023)</xref> shows a progressive increase in MC1R expression throughout melanoma development, from benign moles to metastatic melanoma. Separately <xref rid="btaf408-B20" ref-type="bibr">van der Poel <italic toggle="yes">et al.</italic> (2020)</xref> identified the MC1R <italic toggle="yes">Val60Leu</italic> variant as a significant predictor for high mole counts, confirming the MC1R-Mole link. Together, these findings support this pathway&#8217;s biological plausibility, suggesting a coherent mechanism in melanoma pathogenesis.</p><p>Notably, an alternative pathway, CMM1 <inline-formula id="IE79"><mml:math id="IM79" display="inline" overflow="scroll"><mml:mo>&#8594;</mml:mo></mml:math></inline-formula> MC1R <inline-formula id="IE80"><mml:math id="IM80" display="inline" overflow="scroll"><mml:mo>&#8594;</mml:mo></mml:math></inline-formula> Freckle, also receives high attention weights. This aligns with (<xref rid="btaf408-B1" ref-type="bibr">Bastiaens <italic toggle="yes">et al.</italic> 2001</xref>), who linked MC1R variants to freckle formation, reinforcing its connection to CMM1. As illustrated in <xref rid="btaf408-F4" ref-type="fig">Fig.&#160;4C</xref>, other MC1R-associated conditions, many with dermatological manifestations, show varying correlations with melanoma. These identified pathways deepen our understanding of disease mechanisms and highlight potential research directions.</p></sec></sec></sec><sec><title>4 Discussion</title><p>Building on the demonstrated success of BioGraphFusion, particularly in the CMM1 case study, our future work will focus on two key areas. We plan to validate the framework's efficacy across a broader spectrum of complex diseases to test its generalizability. Concurrently, we aim to enhance our model's core synergistic mechanism to integrate multi-modal data, such as clinical texts, further deepening the interplay between semantic and structural learning for more comprehensive biomedical discovery.</p></sec><sec><title>5 Conclusion</title><p>In this work, we introduce BioGraphFusion, a novel framework synergistically integrating semantic understanding with structural learning for biomedical KGC and KGR. BioGraphFusion enhances the dynamic interplay between these paradigms by using CP decomposition to establish a global semantic context. Building upon this, an LSTM-driven mechanism guides structural learning by dynamically refining relational information and updating semantic understanding during graph propagation. This enables learning context-dependent relation semantics and captures long-range dependencies, moving beyond static interpretations. Complemented by query-guided subgraph construction and a hybrid scoring mechanism, BioGraphFusion fosters a deep, adaptive refinement cycle between structural learning and semantic comprehension. Experimental results show BioGraphFusion consistently outperforms traditional KE models, GNN-based approaches, and ensemble methods across biomedical benchmarks. Its ability to generate comprehensive features through an effective synergy of semantic insights and structural learning establishes it as a powerful tool. Finally, as demonstrated in the CMM1 case study, its capacity to uncover biologically meaningful pathways highlights its potential for advancing biomedical research.</p></sec><sec sec-type="supplementary-material"><title>Supplementary Material</title><supplementary-material id="sup1" position="float" content-type="local-data" orientation="portrait"><label>btaf408_Supplementary_Data</label><media xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="btaf408_supplementary_data.pdf" position="float" orientation="portrait"/></supplementary-material></sec></body><back><sec><title>Author contributions</title><p>Yitong Lin (Data curation [equal], Formal analysis [equal], Investigation [equal], Methodology [equal], Validation, Visualization [equal], Writing&#8212;original draft [equal], Writing&#8212;review &amp; editing [equal]), Jiaying He (Conceptualization, Data curation [equal], Formal analysis [equal], Investigation [equal], Methodology [equal], , Visualization [equal], Writing&#8212;original draft [equal], Writing&#8212;review &amp; editing [equal]), Jiahe Chen (Investigation [equal]), Xinnan Zhu(Investigation [supporting], Visualization [supporting]), Jianwei Zheng (Funding acquisition, Supervision [Lead], Writing&#8212;review &amp; editing [equal]), and Tao Bo (Supervision [equal], Writing&#8212;review &amp; editing [equal])</p></sec><sec><title>Supplementary data</title><p>
<xref rid="sup1" ref-type="supplementary-material">Supplementary data</xref> are available at <italic toggle="yes">Bioinformatics</italic> online.</p><p>Conflict of interest: None declared.</p></sec><sec><title>Funding</title><p>This work was supported in part by the Key Program of Natural Science Foundation of Zhejiang Province [LZ24F030012], and the National Natural Science Foundation of China [62276232].</p></sec><ref-list id="ref1"><title>References</title><ref id="btaf408-B1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Bastiaens</surname><given-names>M</given-names></string-name>, <string-name name-style="western"><surname>ter Huurne</surname><given-names>J</given-names></string-name>, <string-name name-style="western"><surname>Gruis</surname><given-names>N</given-names></string-name></person-group> &#160;<etal>et&#160;al</etal> &#160;<article-title>The melanocortin-1-receptor gene is the major freckle gene</article-title>. <source>Hum Mol Genet</source> &#160;<year>2001</year>;<volume>10</volume>:<fpage>1701</fpage>&#8211;<lpage>8</lpage>.<pub-id pub-id-type="pmid">11487574</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/hmg/10.16.1701</pub-id></mixed-citation></ref><ref id="btaf408-B2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Bodenreider</surname><given-names>O.</given-names></string-name></person-group> &#160;<article-title>The unified medical language system (umls): integrating biomedical terminology</article-title>. <source>Nucleic Acids Res</source> &#160;<year>2004</year>;<volume>32</volume>:<fpage>D267</fpage>&#8211;<lpage>70</lpage>.<pub-id pub-id-type="pmid">14681409</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/nar/gkh061</pub-id><pub-id pub-id-type="pmcid">PMC308795</pub-id></mixed-citation></ref><ref id="btaf408-B3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Chen</surname><given-names>Z</given-names></string-name>, <string-name name-style="western"><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name name-style="western"><surname>Zhao</surname><given-names>B</given-names></string-name></person-group> &#160;<etal>et&#160;al</etal> &#160;<article-title>Knowledge graph completion: a review</article-title>. <source>IEEE Access</source> &#160;<year>2020</year>;<volume>8</volume>:<fpage>192435</fpage>&#8211;<lpage>56</lpage>.</mixed-citation></ref><ref id="btaf408-B4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>G&#233;zsi</surname><given-names>A</given-names></string-name>, <string-name name-style="western"><surname>Antal</surname><given-names>P.</given-names></string-name></person-group> &#160;<article-title>Gnn4dm: a graph neural network-based method to identify overlapping functional disease modules</article-title>. <source>Bioinformatics</source> &#160;<year>2024</year>;<volume>40</volume>:<fpage>btae573</fpage>.<pub-id pub-id-type="pmid">39321259</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/bioinformatics/btae573</pub-id><pub-id pub-id-type="pmcid">PMC11639141</pub-id></mixed-citation></ref><ref id="btaf408-B5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Kolda</surname><given-names>TG</given-names></string-name>, <string-name name-style="western"><surname>Bader</surname><given-names>BW.</given-names></string-name></person-group> &#160;<article-title>Tensor decompositions and applications</article-title>. <source>SIAM Rev</source> &#160;<year>2009</year>;<volume>51</volume>:<fpage>455</fpage>&#8211;<lpage>500</lpage>.</mixed-citation></ref><ref id="btaf408-B6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Kuhn</surname><given-names>M</given-names></string-name>, <string-name name-style="western"><surname>Letunic</surname><given-names>I</given-names></string-name>, <string-name name-style="western"><surname>Jensen</surname><given-names>LJ</given-names></string-name></person-group> &#160;<etal>et&#160;al</etal> &#160;<article-title>The Sider database of drugs and side effects</article-title>. <source>Nucleic Acids Res</source> &#160;<year>2016</year>;<volume>44</volume>:<fpage>D1075</fpage>&#8211;<lpage>D1079</lpage>.<pub-id pub-id-type="pmid">26481350</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/nar/gkv1075</pub-id><pub-id pub-id-type="pmcid">PMC4702794</pub-id></mixed-citation></ref><ref id="btaf408-B7"><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name name-style="western"><surname>Lacroix</surname><given-names>T</given-names></string-name></person-group>,Usunier N, Obozinski G. Canonical tensor decomposition for knowledge base completion. In: Dy J, Krause A (eds.), <italic toggle="yes">Proceedings of the 35th International Conference on Machine Learning</italic>, vol. 80. Proceedings of Machine Learning Research. Stockholm, Sweden: PMLR, <year>2018</year>, <fpage>2863</fpage>&#8211;<lpage>72</lpage>.</mixed-citation></ref><ref id="btaf408-B8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Liang</surname><given-names>K</given-names></string-name>, <string-name name-style="western"><surname>Meng</surname><given-names>L</given-names></string-name>, <string-name name-style="western"><surname>Liu</surname><given-names>M</given-names></string-name></person-group> &#160;<etal>et&#160;al</etal> &#160;<article-title>A survey of knowledge graph reasoning on graph types: static, dynamic, and multi-modal</article-title>. <source>IEEE Trans Pattern Anal Mach Intell</source> &#160;<year>2024</year>;<volume>46</volume>:<fpage>9456</fpage>&#8211;<lpage>78</lpage>.<pub-id pub-id-type="pmid">38941209</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1109/TPAMI.2024.3417451</pub-id></mixed-citation></ref><ref id="btaf408-B9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Liu</surname><given-names>W</given-names></string-name>, <string-name name-style="western"><surname>Cai</surname><given-names>H</given-names></string-name>, <string-name name-style="western"><surname>Cheng</surname><given-names>X</given-names></string-name></person-group> &#160;<etal>et&#160;al</etal> &#160;<article-title>Learning high-order structural and attribute information by knowledge graph attention networks for enhancing knowledge graph embedding</article-title>. <source>Knowledge-Based Syst</source> &#160;<year>2022</year>;<volume>250</volume>:<fpage>109002</fpage>.</mixed-citation></ref><ref id="btaf408-B10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Meng</surname><given-names>S</given-names></string-name>, <string-name name-style="western"><surname>Zhou</surname><given-names>J</given-names></string-name>, <string-name name-style="western"><surname>Chen</surname><given-names>X</given-names></string-name></person-group> &#160;<etal>et&#160;al</etal> &#160;<article-title>Structure-information-based reasoning over the knowledge graph: a survey of methods and applications</article-title>. <source>ACM Trans Knowl Discov Data</source> &#160;<year>2024</year>;<volume>18</volume>:<fpage>1</fpage>&#8211;<lpage>42</lpage>.</mixed-citation></ref><ref id="btaf408-B11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Nickel</surname><given-names>M</given-names></string-name>, <string-name name-style="western"><surname>Murphy</surname><given-names>K</given-names></string-name>, <string-name name-style="western"><surname>Tresp</surname><given-names>V</given-names></string-name></person-group> &#160;<etal>et&#160;al</etal> &#160;<article-title>A review of relational machine learning for knowledge graphs</article-title>. <source>Proc IEEE</source> &#160;<year>2016</year>;<volume>104</volume>:<fpage>11</fpage>&#8211;<lpage>33</lpage>.</mixed-citation></ref><ref id="btaf408-B12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Peng</surname><given-names>C</given-names></string-name>, <string-name name-style="western"><surname>Xia</surname><given-names>F</given-names></string-name>, <string-name name-style="western"><surname>Naseriparsa</surname><given-names>M</given-names></string-name></person-group> &#160;<etal>et&#160;al</etal> &#160;<article-title>Knowledge graphs: opportunities and challenges</article-title>. <source>Artif Intell Rev</source> &#160;<year>2023</year>;<volume>56</volume>:<fpage>1</fpage>&#8211;<lpage>32</lpage>.<pub-id pub-id-type="doi" assigning-authority="pmc">10.1007/s10462-023-10465-9</pub-id><pub-id pub-id-type="pmcid">PMC10068207</pub-id><pub-id pub-id-type="pmid">37362886</pub-id></mixed-citation></ref><ref id="btaf408-B13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Pi&#241;ero</surname><given-names>J</given-names></string-name>, <string-name name-style="western"><surname>Ram&#237;rez-Anguita</surname><given-names>JM</given-names></string-name>, <string-name name-style="western"><surname>Sa&#252;ch-Pitarch</surname><given-names>J</given-names></string-name></person-group> &#160;<etal>et&#160;al</etal> &#160;<article-title>The disgenet knowledge platform for disease genomics: 2019 update</article-title>. <source>Nucleic Acids Res</source> &#160;<year>2020</year>;<volume>48</volume>:<fpage>D845</fpage>&#8211;<lpage>D855</lpage>.<pub-id pub-id-type="pmid">31680165</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/nar/gkz1021</pub-id><pub-id pub-id-type="pmcid">PMC7145631</pub-id></mixed-citation></ref><ref id="btaf408-B14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Qiao</surname><given-names>G</given-names></string-name>, <string-name name-style="western"><surname>Wang</surname><given-names>G</given-names></string-name>, <string-name name-style="western"><surname>Li</surname><given-names>Y</given-names></string-name></person-group> &#160;<etal>et&#160;al</etal> &#160;<article-title>Causal enhanced drug-target interaction prediction based on graph generation and multi-source information fusion</article-title>. <source>Bioinformatics</source> &#160;<year>2024</year>;<volume>40</volume> page :<fpage>btae570</fpage>.<pub-id pub-id-type="pmid">39312682</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/bioinformatics/btae570</pub-id><pub-id pub-id-type="pmcid">PMC11639159</pub-id></mixed-citation></ref><ref id="btaf408-B15"><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name name-style="western"><surname>Shen</surname><given-names>J</given-names></string-name>, <string-name name-style="western"><surname>Wang</surname><given-names>C</given-names></string-name>, <string-name name-style="western"><surname>Gong</surname><given-names>L</given-names></string-name></person-group> &#160;<etal>et&#160;al</etal> Joint language semantic and structure embedding for knowledge graph completion. In: <italic toggle="yes">Proceedings of the 29th International Conference on Computational Linguistics.</italic> Gyeongju, Republic of Korea: International Committee on Computational Linguistics; <year>2022</year>, <fpage>1965</fpage>&#8211;<lpage>78</lpage>.</mixed-citation></ref><ref id="btaf408-B16"><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name name-style="western"><surname>Su</surname><given-names>D, Djureinovic D, Schoenfeld D</given-names></string-name></person-group> &#160;<etal>et&#160;al</etal> Melanocortin 1 receptor (mc1r) expression as a marker of progression in melanoma. <italic toggle="yes">Research Square</italic>, <year>2023</year>: rs&#8211;3.</mixed-citation></ref><ref id="btaf408-B17"><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name name-style="western"><surname>Sun</surname><given-names>Z, Deng ZH, Nie JY</given-names></string-name></person-group> &#160;<etal>et&#160;al</etal> Rotate: knowledge graph embedding by relational rotation in complex space. In: <italic toggle="yes">ICLR,</italic> New Orleans, LA, USA: OpenReview.net., <year>2019.</year></mixed-citation></ref><ref id="btaf408-B18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Szklarczyk</surname><given-names>D</given-names></string-name>, <string-name name-style="western"><surname>Santos</surname><given-names>A</given-names></string-name>, <string-name name-style="western"><surname>von Mering</surname><given-names>C</given-names></string-name></person-group> &#160;<etal>et&#160;al</etal> &#160;<article-title>Stitch 5: augmenting protein&#8211;chemical interaction networks with tissue and affinity data</article-title>. <source>Nucleic Acids Res</source> &#160;<year>2016</year>;<volume>44</volume>:<fpage>D380</fpage>&#8211;<lpage>D384</lpage>.<pub-id pub-id-type="pmid">26590256</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/nar/gkv1277</pub-id><pub-id pub-id-type="pmcid">PMC4702904</pub-id></mixed-citation></ref><ref id="btaf408-B19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Tang</surname><given-names>K</given-names></string-name>, <string-name name-style="western"><surname>Li</surname><given-names>S</given-names></string-name>, <string-name name-style="western"><surname>Tang</surname><given-names>J</given-names></string-name></person-group> &#160;<etal>et&#160;al</etal> &#160;<article-title>Fusing structural information with knowledge enhanced text representation for knowledge graph completion</article-title>. <source>Data Min Knowl Disc</source> &#160;<year>2024</year>;<volume>38</volume>:<fpage>1316</fpage>&#8211;<lpage>33</lpage>.</mixed-citation></ref><ref id="btaf408-B20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>van der Poel</surname><given-names>LAJ</given-names></string-name>, <string-name name-style="western"><surname>Bergman</surname><given-names>W</given-names></string-name>, <string-name name-style="western"><surname>Gruis</surname><given-names>NA</given-names></string-name></person-group> &#160;<etal>et&#160;al</etal> &#160;<article-title>The role of mc1r gene variants and phenotypical features in predicting high nevus count</article-title>. <source>Melanoma Res</source> &#160;<year>2020</year>;<volume>30</volume>:<fpage>511</fpage>&#8211;<lpage>4</lpage>.<pub-id pub-id-type="pmid">32732695</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1097/CMR.0000000000000687</pub-id></mixed-citation></ref><ref id="btaf408-B21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Vilela</surname><given-names>J</given-names></string-name>, <string-name name-style="western"><surname>Asif</surname><given-names>M</given-names></string-name>, <string-name name-style="western"><surname>Marques</surname><given-names>AR</given-names></string-name></person-group> &#160;<etal>et&#160;al</etal> &#160;<article-title>Biomedical knowledge graph embeddings for personalized medicine: predicting disease-gene associations</article-title>. <source>Exp Syst</source> &#160;<year>2023</year>;<volume>40</volume>:<fpage>e13181</fpage>.</mixed-citation></ref><ref id="btaf408-B22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Wang</surname><given-names>X</given-names></string-name>, <string-name name-style="western"><surname>Yang</surname><given-names>K</given-names></string-name>, <string-name name-style="western"><surname>Jia</surname><given-names>T</given-names></string-name></person-group> &#160;<etal>et&#160;al</etal> &#160;<article-title>Kdgene: knowledge graph completion for disease gene prediction using interactional tensor decomposition</article-title>. <source>Brief Bioinform</source> &#160;<year>2024a</year>;<volume>25</volume>:<fpage>bbae161</fpage>.<pub-id pub-id-type="pmid">38605639</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1093/bib/bbae161</pub-id><pub-id pub-id-type="pmcid">PMC11009469</pub-id></mixed-citation></ref><ref id="btaf408-B23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><string-name name-style="western"><surname>Wang</surname><given-names>Y</given-names></string-name>, <string-name name-style="western"><surname>Yang</surname><given-names>Z</given-names></string-name>, <string-name name-style="western"><surname>Yao</surname><given-names>Q</given-names></string-name></person-group> &#160;<etal>et&#160;al</etal> &#160;<article-title>Accurate and interpretable drug-drug interaction prediction enabled by knowledge subgraph learning</article-title>. <source>Commun Med (Lond)</source> &#160;<year>2024b</year>;<volume>4</volume>:<fpage>59</fpage>.<pub-id pub-id-type="pmid">38548835</pub-id><pub-id pub-id-type="doi" assigning-authority="pmc">10.1038/s43856-024-00486-y</pub-id><pub-id pub-id-type="pmcid">PMC10978847</pub-id></mixed-citation></ref><ref id="btaf408-B24"><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name name-style="western"><surname>Yao</surname><given-names>L</given-names></string-name>, <string-name name-style="western"><surname>Mao</surname><given-names>C</given-names></string-name>, <string-name name-style="western"><surname>Luo</surname><given-names>Y.</given-names></string-name></person-group> Kg-bert: bert for knowledge graph completion. arXiv, Preprint arXiv: 1909.03193, <year>2019</year>.</mixed-citation></ref><ref id="btaf408-B25"><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name name-style="western"><surname>Yu</surname><given-names>D, Yang Y, Zhang R</given-names></string-name></person-group>&#160;<etal>et&#160;al</etal> Knowledge embedding based graph convolutional network. In: <italic toggle="yes">Proceedings of the Web Conference 2021</italic>. New York, NY, USA: Association for Computing Machinery, <year>2021</year>, <fpage>1619</fpage>&#8211;<lpage>28</lpage>.</mixed-citation></ref><ref id="btaf408-B26"><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name name-style="western"><surname>Zhang</surname><given-names>Y</given-names></string-name>, <string-name name-style="western"><surname>Yao</surname><given-names>Q.</given-names></string-name></person-group> Knowledge graph reasoning with relational digraph. In: <italic toggle="yes">Proceedings of the ACM Web Conference 2022</italic>. New York: Association for Computing Machinery, <year>2022</year>, <fpage>912</fpage>&#8211;<lpage>24</lpage>.</mixed-citation></ref><ref id="btaf408-B27"><mixed-citation publication-type="other"><person-group person-group-type="author"><string-name name-style="western"><surname>Zhang</surname><given-names>Y, Zhou Z, Yao Q</given-names></string-name></person-group> &#160;<etal>et&#160;al</etal> Adaprop: Learning adaptive propagation for graph neural network based knowledge graph reasoning. In: <italic toggle="yes">Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</italic>. New York: Association for Computing Machinery, <year>2023</year>, <fpage>3446</fpage>&#8211;<lpage>57</lpage>.</mixed-citation></ref></ref-list></back></article></pmc-articleset>